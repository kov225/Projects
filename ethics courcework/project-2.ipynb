{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5954941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This project is confusing. We cannot recreate the R code here as factoring in R is different than pandas categoricals. \n",
    "#I dont know which columns are valid and invalid in demo code so I am going with my judgement from all the knowledge I acumulated from the courcework here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc80a865",
   "metadata": {},
   "source": [
    "# DELIVERABLE -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d450c1",
   "metadata": {},
   "source": [
    "# Context and Fairness Definition\n",
    "\n",
    "**Context.** The Civilian Complaint Review Board (CCRB) evaluates civilian allegations against NYPD officers and decides whether each allegation is valid or invalid, and this dataset contains many years of those allegation-level decisions along with officer and complainant attributes.\n",
    "\n",
    "**Fairness definition.** In this project I define fairness as a clear, argued commitment to what we protect, how we measure it, and where we intervene in the workflow. I treat **race** and **gender** as protected because they are legally and socially salient in policing outcomes, and unequal error burdens across these attributes risk compounding historic disadvantage and eroding public trust. My primary concern is two kinds of harm: missed true harms to complainants and unjust false positives for officers. After considering metrics discussed in Mulligan et al. such as **Demographic Parity**, **Equalized Odds**, **Predictive Value Parity**, and **calibration by group**, I adopt an **Equal Opportunity style criterion** within the Equalized Odds family that prioritizes **parity in true positive rates** across protected groups, since the CCRB’s accountability mission is to recognise genuine misconduct equally across groups. I explicitly prefer this over demographic parity, which can be misleading when base rates differ and can force equalisation that ignores case facts, and over predictive parity, which can tolerate unequal sensitivity and leave some groups with systematically lower chances of having true harms recognised. I accept that this choice may yield different positive prediction rates across groups; my goal is to avoid unequal under-detection of genuine misconduct while I monitor **false positive rate** gaps and **calibration** by group as guardrails to protect officers from unfair sanctioning. I evaluate gender alongside race because alleged harms and disciplinary outcomes can vary by gender in policy-relevant ways, and excluding gender could mask unequal burdens. Given New York City’s history of strained police community relations and racial disparities in enforcement, fairness here is not only statistical but also about public trust for complainants, officers, CCRB staff, NYPD leadership, advocacy groups, and the public. In line with Mulligan’s call for shared vocabularies and explicit scope, I will publish decision criteria and thresholds, audit **TPR** and **FPR** by group on a schedule, show calibration by group, and state trade offs up front so stakeholders understand both the measurement and the actions that follow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08f1645",
   "metadata": {},
   "source": [
    "# DELIVERABLE -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d3661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import patsy as pt\n",
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b853e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes -> officers, complaints, allegations:\n",
      "(95322, 14) (136395, 14) (411977, 18) (13980, 13)\n",
      "\n",
      "Key-like columns:\n",
      "Officers: ['Tax ID', 'Current Rank Abbreviation', 'Current Rank', 'Total Complaints', 'Total Substantiated Complaints']\n",
      "Complaints: ['Complaint Id', 'CCRB Complaint Disposition']\n",
      "Allegations: ['Complaint Id', 'Complaint Officer Number', 'Tax ID', 'Officer Rank Abbreviation At Incident', 'Officer Rank At Incident', 'Allegation Record Identity', 'Allegation', 'CCRB Allegation Disposition', 'NYPD Allegation Disposition']\n",
      "Penalties: ['Complaint Id', 'Tax ID', 'Non-APU NYPD Penalty Report Date', 'APU CCRB Trial Recommended Penalty', 'APU Trial Commissioner Recommended Penalty', 'APU Plea Agreed Penalty', 'NYPD Officer Penalty']\n"
     ]
    }
   ],
   "source": [
    "OFFICERS_PATH   = r\"E:\\DSC451-ethics\\project-2\\Civilian_Complaint_Review_Board__Police_Officers_20251027.csv\"\n",
    "COMPLAINTS_PATH = r\"E:\\DSC451-ethics\\project-2\\Civilian_Complaint_Review_Board__Complaints_Against_Police_Officers_20251027.csv\"\n",
    "ALLEGATIONS_PATH= r\"E:\\DSC451-ethics\\project-2\\Civilian_Complaint_Review_Board__Allegations_Against_Police_Officers_20251027.csv\"\n",
    "PENALTIES_CSV  = r\"E:\\DSC451-ethics\\project-2\\Civilian_Complaint_Review_Board__Penalties_20251027.csv\"\n",
    "\n",
    "officers   = pd.read_csv(OFFICERS_PATH,   na_values=[\"\", \"NA\"], low_memory=False)\n",
    "complaints = pd.read_csv(COMPLAINTS_PATH, na_values=[\"\", \"NA\"], low_memory=False)\n",
    "allegations= pd.read_csv(ALLEGATIONS_PATH,na_values=[\"\", \"NA\"], low_memory=False)\n",
    "penalties   = pd.read_csv(PENALTIES_CSV,   na_values=[\"\", \"NA\"], low_memory=False)\n",
    "\n",
    "print(\"Shapes -> officers, complaints, allegations:\")\n",
    "print(officers.shape, complaints.shape, allegations.shape, penalties.shape)\n",
    "\n",
    "def cols(df): \n",
    "    return [c for c in df.columns if \"Complaint\" in c or \"Tax\" in c or \"Allegation\" in c or \"Penalty\" in c or \"Rank\" in c][:15]\n",
    "\n",
    "print(\"\\nKey-like columns:\")\n",
    "print(\"Officers:\", cols(officers))\n",
    "print(\"Complaints:\", cols(complaints))\n",
    "print(\"Allegations:\", cols(allegations))\n",
    "print(\"Penalties:\", cols(penalties))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb86b359",
   "metadata": {},
   "source": [
    "Just reading all files and wrote and extra line of code in which it considers all NA or empty strings as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49d60412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Missing values: Officers (rows=95322, cols=14) ===\n",
      "Total missing cells: 81 out of 1,334,508\n",
      "Rows with any missing: 81\n",
      "                         column  n_missing  pct_missing\n",
      "                      Shield No         58         0.06\n",
      "                 Officer Gender         23         0.02\n",
      "                     As Of Date          0         0.00\n",
      "                         Tax ID          0         0.00\n",
      "Active Per Last Reported Status          0         0.00\n",
      "      Last Reported Active Date          0         0.00\n",
      "             Officer First Name          0         0.00\n",
      "              Officer Last Name          0         0.00\n",
      "                   Officer Race          0         0.00\n",
      "      Current Rank Abbreviation          0         0.00\n",
      "                   Current Rank          0         0.00\n",
      "                Current Command          0         0.00\n",
      "               Total Complaints          0         0.00\n",
      " Total Substantiated Complaints          0         0.00\n",
      "\n",
      "=== Missing values: Complaints (rows=136395, cols=14) ===\n",
      "Total missing cells: 18,200 out of 1,909,530\n",
      "Rows with any missing: 12,523\n",
      "                         column  n_missing  pct_missing\n",
      "                  Incident Hour       5651         4.14\n",
      "      Location Type Of Incident       3420         2.51\n",
      "Precinct Of Incident Occurrence       3413         2.50\n",
      "      Reason for Police Contact       2292         1.68\n",
      "                  Incident Date       1255         0.92\n",
      " Borough Of Incident Occurrence       1223         0.90\n",
      "    Outcome Of Police Encounter        946         0.69\n",
      "                     As Of Date          0         0.00\n",
      "                   Complaint Id          0         0.00\n",
      "             CCRB Received Date          0         0.00\n",
      "                     Close Date          0         0.00\n",
      "     CCRB Complaint Disposition          0         0.00\n",
      "                   BWC Evidence          0         0.00\n",
      "                 Video Evidence          0         0.00\n",
      "\n",
      "=== Missing values: Allegations (rows=411977, cols=18) ===\n",
      "Total missing cells: 1,639,569 out of 7,415,586\n",
      "Rows with any missing: 411,731\n",
      "                                     column  n_missing  pct_missing\n",
      "                NYPD Allegation Disposition     388961        94.41\n",
      "   Victim / Alleged Victim Race / Ethnicity     372656        90.46\n",
      "                                     Tax ID     164305        39.88\n",
      "      Officer Rank Abbreviation At Incident     162740        39.50\n",
      "                   Officer Rank At Incident     162740        39.50\n",
      "                Officer Command At Incident     132215        32.09\n",
      "      Victim / Alleged Victim Race (Legacy)     103808        25.20\n",
      "Victim/Alleged Victim Age Range At Incident      85020        20.64\n",
      "               Victim/Alleged Victim Gender      46595        11.31\n",
      "          Officer Days On Force At Incident      20518         4.98\n",
      "CCRB Investigations Division Recommendation         11         0.00\n",
      "                                 As Of Date          0         0.00\n",
      "                               Complaint Id          0         0.00\n",
      "                   Complaint Officer Number          0         0.00\n",
      "                 Allegation Record Identity          0         0.00\n",
      "                                  FADO Type          0         0.00\n",
      "                                 Allegation          0         0.00\n",
      "                CCRB Allegation Disposition          0         0.00\n",
      "\n",
      "=== Missing values: Penalties (rows=13980, cols=13) ===\n",
      "Total missing cells: 76,893 out of 181,740\n",
      "Rows with any missing: 13,980\n",
      "                                    column  n_missing  pct_missing\n",
      "APU Trial Commissioner Recommended Penalty      13668        97.77\n",
      "        APU CCRB Trial Recommended Penalty      13395        95.82\n",
      "                   APU Plea Agreed Penalty      13285        95.03\n",
      "                          APU Closing Date      12074        86.37\n",
      "                           APU Case Status      11197        80.09\n",
      "           Board Discipline Recommendation       7753        55.46\n",
      "          Non-APU NYPD Penalty Report Date       3618        25.88\n",
      "                      NYPD Officer Penalty       1903        13.61\n",
      "                                As Of Date          0         0.00\n",
      "                              Complaint Id          0         0.00\n",
      "                                    Tax ID          0         0.00\n",
      "    CCRB Substantiated Officer Disposition          0         0.00\n",
      "                            Officer is_APU          0         0.00\n"
     ]
    }
   ],
   "source": [
    "#checking for missing values\n",
    "def missing_report(df: pd.DataFrame, name: str, top=20):\n",
    "    rep = (\n",
    "        pd.DataFrame({\n",
    "            \"column\": df.columns,\n",
    "            \"n_missing\": df.isna().sum().values,\n",
    "            \"pct_missing\": (df.isna().mean().values * 100).round(2)\n",
    "        })\n",
    "        .sort_values([\"n_missing\",\"pct_missing\"], ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    rows_with_any_missing = int(df.isna().any(axis=1).sum())\n",
    "    total_cells = df.shape[0] * df.shape[1]\n",
    "    total_missing = int(df.isna().sum().sum())\n",
    "    print(f\"\\n=== Missing values: {name} (rows={len(df)}, cols={df.shape[1]}) ===\")\n",
    "    print(f\"Total missing cells: {total_missing:,} out of {total_cells:,}\")\n",
    "    print(f\"Rows with any missing: {rows_with_any_missing:,}\")\n",
    "    print(rep.head(top).to_string(index=False))\n",
    "\n",
    "# Run for each table you loaded in Step 1\n",
    "missing_report(officers,   \"Officers\")\n",
    "missing_report(complaints, \"Complaints\")\n",
    "missing_report(allegations,\"Allegations\")\n",
    "missing_report(penalties,  \"Penalties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfd9f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISP = \"CCRB Complaint Disposition\"\n",
    "KEY  = \"Complaint Id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b2a44f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allegations now has 'CCRB Complaint Disposition'. Missing values: 0 of 411,977\n",
      "\n",
      "Top complaint dispositions now on Allegations:\n",
      "CCRB Complaint Disposition\n",
      "Complainant Uncooperative                   93737\n",
      "Unsubstantiated                             86396\n",
      "Unfounded                                   34139\n",
      "Complaint Withdrawn                         33126\n",
      "Substantiated (Charges)                     29562\n",
      "Complainant Unavailable                     26255\n",
      "Exonerated                                  19743\n",
      "Alleged Victim Uncooperative                13219\n",
      "Closed - Pending Litigation                 11335\n",
      "Substantiated (Command Discipline A)        11221\n",
      "Officer(s) Unidentified                      9029\n",
      "Substantiated (Command Discipline B)         8642\n",
      "Unable to Determine                          8250\n",
      "Substantiated (Formalized Training)          6311\n",
      "Alleged Victim Unavailable                   4654\n",
      "Substantiated (Command Discipline)           3303\n",
      "Within NYPD Guidelines                       2940\n",
      "OMB PEG Directive Closure                    2112\n",
      "Substantiated (Command Lvl Instructions)     1912\n",
      "SRAD Closure                                 1774\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if DISP not in allegations.columns:\n",
    "    allegations = allegations.merge(\n",
    "        complaints[[KEY, DISP]],\n",
    "        on=KEY,\n",
    "        how=\"left\",\n",
    "        validate=\"many_to_one\"   # each complaint has one disposition, many allegations reference it\n",
    "    )\n",
    "\n",
    "# Sanity: confirm the column is present and inspect missingness\n",
    "assert DISP in allegations.columns, \"Disposition column not found on Allegations after merge.\"\n",
    "\n",
    "n_miss = allegations[DISP].isna().sum()\n",
    "print(f\"Allegations now has '{DISP}'. Missing values: {n_miss:,} of {len(allegations):,}\")\n",
    "\n",
    "# Peek at the most common labels so we know what we are about to map\n",
    "print(\"\\nTop complaint dispositions now on Allegations:\")\n",
    "print(allegations[DISP].value_counts(dropna=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8204e005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket\n",
      "EXCLUDED    198240\n",
      "INVALID     151468\n",
      "VALID        62269\n",
      "Name: count, dtype: int64\n",
      "\n",
      "All dispositions captured by the mapping.\n"
     ]
    }
   ],
   "source": [
    "def _norm(s):\n",
    "    return \"\" if pd.isna(s) else str(s).strip()\n",
    "\n",
    "# Valid: any \"Substantiated (...)\" label\n",
    "def is_valid(s):\n",
    "    return _norm(s).startswith(\"Substantiated\")\n",
    "\n",
    "# Policy choice for main analysis:\n",
    "# Count \"Unable to Determine\" as INVALID (we will do a sensitivity later excluding it)\n",
    "INVALID_SET = {\n",
    "    \"Unfounded\",\n",
    "    \"Exonerated\",\n",
    "    \"Within NYPD Guidelines\",\n",
    "    \"Unsubstantiated\",\n",
    "    \"Unable to Determine\"\n",
    "}\n",
    "def is_invalid(s):\n",
    "    return _norm(s) in INVALID_SET\n",
    "\n",
    "# Process closures to EXCLUDE from decided set\n",
    "EXCLUDED_PREFIXES = {\n",
    "    \"Complainant Uncooperative\",\n",
    "    \"Alleged Victim Uncooperative\",\n",
    "    \"Complainant Unavailable\",\n",
    "    \"Alleged Victim Unavailable\",\n",
    "    \"Complaint Withdrawn\",\n",
    "    \"Officer(s) Unidentified\",\n",
    "    \"Victim Unidentified\",\n",
    "    \"Mediation Attempted\",\n",
    "    \"Mediated\",\n",
    "    \"Closed - Pending Litigation\",\n",
    "    \"OMB PEG Directive Closure\",\n",
    "    \"SRAD Closure\",\n",
    "    \"Administratively Closed\",\n",
    "    \"Miscellaneous\",\n",
    "    \"Miscellaneous - Subject Retired\",\n",
    "    \"Miscellaneous - Subject Resigned\",\n",
    "    \"Witness Uncooperative\",\n",
    "    \"Witness Unavailable\",\n",
    "}\n",
    "def is_excluded(s):\n",
    "    s = _norm(s)\n",
    "    return any(s.startswith(p) for p in EXCLUDED_PREFIXES)\n",
    "\n",
    "allegations[\"ccrb_valid\"]   = allegations[DISP].map(is_valid)\n",
    "allegations[\"ccrb_invalid\"] = allegations[DISP].map(is_invalid)\n",
    "allegations[\"ccrb_exclude\"] = allegations[DISP].map(is_excluded)\n",
    "\n",
    "# Sanity bucket to confirm mapping coverage\n",
    "bucket = np.where(allegations[\"ccrb_valid\"],   \"VALID\",\n",
    "         np.where(allegations[\"ccrb_invalid\"], \"INVALID\",\n",
    "         np.where(allegations[\"ccrb_exclude\"], \"EXCLUDED\", \"UNCAPTURED\")))\n",
    "\n",
    "print(pd.Series(bucket, name=\"bucket\").value_counts().sort_index())\n",
    "\n",
    "# If anything remains UNCATURED, print top labels so we can improve rules\n",
    "uncaptured = allegations.loc[(bucket==\"UNCAPTURED\"), DISP].value_counts()\n",
    "if len(uncaptured):\n",
    "    print(\"\\nUNCAPTURED labels (review mapping):\")\n",
    "    print(uncaptured.head(20))\n",
    "else:\n",
    "    print(\"\\nAll dispositions captured by the mapping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decided shape: (213737, 23)\n",
      "Overall substantiation rate (decided): 0.2913  (29.13%)\n",
      "CCRB Complaint Disposition\n",
      "Unsubstantiated                         86396\n",
      "Unfounded                               34139\n",
      "Substantiated (Charges)                 29562\n",
      "Exonerated                              19743\n",
      "Substantiated (Command Discipline A)    11221\n",
      "Substantiated (Command Discipline B)     8642\n",
      "Unable to Determine                      8250\n",
      "Substantiated (Formalized Training)      6311\n",
      "Substantiated (Command Discipline)       3303\n",
      "Within NYPD Guidelines                   2940\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "decided = allegations[(allegations[\"ccrb_valid\"]) | (allegations[\"ccrb_invalid\"])].copy()\n",
    "\n",
    "# Binary outcome: 1 = substantiated, 0 = not substantiated\n",
    "decided[\"outcome_bin\"] = decided[\"ccrb_valid\"].astype(int)\n",
    "\n",
    "# Report\n",
    "n_decided = len(decided)\n",
    "substantiation_rate = decided[\"outcome_bin\"].mean()\n",
    "\n",
    "print(f\"Decided shape: {decided.shape}\")\n",
    "print(f\"Overall substantiation rate (decided): {substantiation_rate:.4f}  ({substantiation_rate*100:.2f}%)\")\n",
    "print(decided[\"CCRB Complaint Disposition\"].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20911de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage: {'decided_total': 213737, 'with_TaxID': 182778, 'with_officer_race': 182764, 'with_officer_gender': 182693}\n",
      "\n",
      "By officer race (includes 'Unknown'):\n",
      "    officer_race_f      rate      n    ci_low   ci_high\n",
      "0            White  0.294861  95350  0.291975  0.297763\n",
      "1         Hispanic  0.350442  51201  0.346321  0.354586\n",
      "2          Unknown  0.144255  30973  0.140386  0.148212\n",
      "3            Black  0.304178  26810  0.298699  0.309712\n",
      "4            Asian  0.384440   9216  0.374558  0.394418\n",
      "5  American Indian  0.240642    187  0.184989  0.306735\n",
      "\n",
      "By officer gender (includes 'Unknown'):\n",
      "  officer_gender_f      rate       n    ci_low   ci_high\n",
      "0             Male  0.316396  166933  0.314170  0.318632\n",
      "1          Unknown  0.144537   31044  0.140669  0.148492\n",
      "2           Female  0.314867   15686  0.307644  0.322180\n",
      "3     TGNC / Other  0.351351      74  0.252382  0.464992\n",
      "\n",
      "By officer race (known only):\n",
      "    officer_race_f      rate      n    ci_low   ci_high\n",
      "0            White  0.294861  95350  0.291975  0.297763\n",
      "1         Hispanic  0.350442  51201  0.346321  0.354586\n",
      "2            Black  0.304178  26810  0.298699  0.309712\n",
      "3            Asian  0.384440   9216  0.374558  0.394418\n",
      "4  American Indian  0.240642    187  0.184989  0.306735\n",
      "\n",
      "By officer gender (known only):\n",
      "  officer_gender_f      rate       n    ci_low   ci_high\n",
      "0             Male  0.316396  166933  0.314170  0.318632\n",
      "1           Female  0.314867   15686  0.307644  0.322180\n",
      "2     TGNC / Other  0.351351      74  0.252382  0.464992\n"
     ]
    }
   ],
   "source": [
    "#as I chose equal opportunity as my fairness metric\n",
    "# Attach officer race/gender to the decided set\n",
    "decided = decided.merge(\n",
    "    officers[[\"Tax ID\", \"Officer Race\", \"Officer Gender\"]],\n",
    "    on=\"Tax ID\", how=\"left\"\n",
    ").rename(columns={\"Officer Race\":\"officer_race\", \"Officer Gender\":\"officer_gender\"})\n",
    "\n",
    "coverage = {\n",
    "    \"decided_total\": len(decided),\n",
    "    \"with_TaxID\": decided[\"Tax ID\"].notna().sum(),\n",
    "    \"with_officer_race\": decided[\"officer_race\"].notna().sum(),\n",
    "    \"with_officer_gender\": decided[\"officer_gender\"].notna().sum(),\n",
    "}\n",
    "print(\"Coverage:\", coverage)\n",
    "\n",
    "\n",
    "\n",
    "def rates_with_ci(frame: pd.DataFrame, group_col: str) -> pd.DataFrame:\n",
    "    t = (frame.groupby(group_col, dropna=False)[\"outcome_bin\"]\n",
    "         .agg(rate=\"mean\", n=\"count\")\n",
    "         .sort_values(\"n\", ascending=False)\n",
    "         .reset_index())\n",
    "    # Wilson 95% CI\n",
    "    ci_low, ci_high = proportion_confint(\n",
    "        count=(t[\"rate\"]*t[\"n\"]).round().astype(int),\n",
    "        nobs=t[\"n\"], method=\"wilson\"\n",
    "    )\n",
    "    t[\"ci_low\"]  = ci_low\n",
    "    t[\"ci_high\"] = ci_high\n",
    "    return t\n",
    "\n",
    "# Include \"Unknown\" buckets for transparency, then compute known-only views\n",
    "decided[\"officer_race_f\"]   = decided[\"officer_race\"].fillna(\"Unknown\")\n",
    "decided[\"officer_gender_f\"] = decided[\"officer_gender\"].fillna(\"Unknown\")\n",
    "\n",
    "by_race_all   = rates_with_ci(decided, \"officer_race_f\")\n",
    "by_gender_all = rates_with_ci(decided, \"officer_gender_f\")\n",
    "\n",
    "print(\"\\nBy officer race (includes 'Unknown'):\")\n",
    "print(by_race_all)\n",
    "\n",
    "print(\"\\nBy officer gender (includes 'Unknown'):\")\n",
    "print(by_gender_all)\n",
    "\n",
    "# Known-only versions \n",
    "by_race_known   = rates_with_ci(decided[decided[\"officer_race_f\"]   != \"Unknown\"], \"officer_race_f\")\n",
    "by_gender_known = rates_with_ci(decided[decided[\"officer_gender_f\"] != \"Unknown\"], \"officer_gender_f\")\n",
    "\n",
    "print(\"\\nBy officer race (known only):\")\n",
    "print(by_race_known)\n",
    "\n",
    "print(\"\\nBy officer gender (known only):\")\n",
    "print(by_gender_known)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04cb890e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Disparities vs reference (officer race):\n",
      "    officer_race_f      n      rate ref_group  risk_diff_vs_ref  \\\n",
      "0            White  95350  0.294861     White          0.000000   \n",
      "1         Hispanic  51201  0.350442     White          0.055581   \n",
      "2            Black  26810  0.304178     White          0.009317   \n",
      "3            Asian   9216  0.384440     White          0.089579   \n",
      "4  American Indian    187  0.240642     White         -0.054219   \n",
      "\n",
      "   risk_ratio_vs_ref  \n",
      "0           1.000000  \n",
      "1           1.188500  \n",
      "2           1.031596  \n",
      "3           1.303801  \n",
      "4           0.816119  \n",
      "\n",
      "Disparities vs reference (officer gender):\n",
      "  officer_gender_f       n      rate ref_group  risk_diff_vs_ref  \\\n",
      "0             Male  166933  0.316396      Male          0.000000   \n",
      "1           Female   15686  0.314867      Male         -0.001530   \n",
      "2     TGNC / Other      74  0.351351      Male          0.034955   \n",
      "\n",
      "   risk_ratio_vs_ref  \n",
      "0           1.000000  \n",
      "1           0.995165  \n",
      "2           1.110478  \n",
      "\n",
      "EO flags for officer_race (>|3| pp):\n",
      "    officer_race_f      n      rate  abs_diff_vs_ref eo_flag\n",
      "0            White  95350  0.294861         0.000000      OK\n",
      "1         Hispanic  51201  0.350442         0.055581    FLAG\n",
      "2            Black  26810  0.304178         0.009317      OK\n",
      "3            Asian   9216  0.384440         0.089579    FLAG\n",
      "4  American Indian    187  0.240642         0.054219    FLAG\n",
      "\n",
      "EO flags for officer_gender (>|3| pp):\n",
      "  officer_gender_f       n      rate  abs_diff_vs_ref eo_flag\n",
      "0             Male  166933  0.316396         0.000000      OK\n",
      "1           Female   15686  0.314867         0.001530      OK\n",
      "2     TGNC / Other      74  0.351351         0.034955    FLAG\n"
     ]
    }
   ],
   "source": [
    "def disparity_vs_ref(rate_table: pd.DataFrame, group_col: str) -> pd.DataFrame:\n",
    "    # Identify reference as the largest-N group\n",
    "    ref = rate_table.loc[rate_table[\"n\"].idxmax()]\n",
    "    ref_rate  = ref[\"rate\"]\n",
    "    ref_group = ref[group_col]\n",
    "    out = rate_table.copy()\n",
    "    out[\"ref_group\"] = ref_group\n",
    "    out[\"risk_diff_vs_ref\"]  = out[\"rate\"] - ref_rate\n",
    "    out[\"risk_ratio_vs_ref\"] = np.where(ref_rate > 0, out[\"rate\"] / ref_rate, np.nan)\n",
    "    # Order: biggest samples first, then largest absolute difference\n",
    "    return out.sort_values([\"n\", \"risk_diff_vs_ref\"], ascending=[False, True])\n",
    "\n",
    "disp_race   = disparity_vs_ref(by_race_known,   \"officer_race_f\")\n",
    "disp_gender = disparity_vs_ref(by_gender_known, \"officer_gender_f\")\n",
    "\n",
    "print(\"\\nDisparities vs reference (officer race):\")\n",
    "print(disp_race[[\"officer_race_f\",\"n\",\"rate\",\"ref_group\",\"risk_diff_vs_ref\",\"risk_ratio_vs_ref\"]])\n",
    "\n",
    "print(\"\\nDisparities vs reference (officer gender):\")\n",
    "print(disp_gender[[\"officer_gender_f\",\"n\",\"rate\",\"ref_group\",\"risk_diff_vs_ref\",\"risk_ratio_vs_ref\"]])\n",
    "\n",
    "# Optional: simple EO flags if absolute difference > 3 percentage points\n",
    "EO_THRESHOLD = 0.03  # 3 pp\n",
    "def eo_flags(rate_table: pd.DataFrame, label: str):\n",
    "    ref = rate_table.loc[rate_table[\"n\"].idxmax(), \"rate\"]\n",
    "    flagged = rate_table.assign(\n",
    "        abs_diff_vs_ref = (rate_table[\"rate\"] - ref).abs(),\n",
    "        eo_flag = np.where((rate_table[\"rate\"] - ref).abs() > EO_THRESHOLD, \"FLAG\", \"OK\")\n",
    "    )\n",
    "    print(f\"\\nEO flags for {label} (>|{EO_THRESHOLD*100:.0f}| pp):\")\n",
    "    print(flagged[[rate_table.columns[0],\"n\",\"rate\",\"abs_diff_vs_ref\",\"eo_flag\"]])\n",
    "\n",
    "eo_flags(by_race_known,   \"officer_race\")\n",
    "eo_flags(by_gender_known, \"officer_gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baaaf4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\souq_e_commerce_3_11\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adjusted logistic regression: odds on substantiation\n",
      "                                                        Coef.    Std.Err.  \\\n",
      "Intercept                                          -13.968535  183.565302   \n",
      "C(officer_race)[T.Asian]                            -0.157357    0.184802   \n",
      "C(officer_race)[T.Black]                            -0.125729    0.183834   \n",
      "C(officer_race)[T.Hispanic]                         -0.053577    0.183583   \n",
      "C(officer_race)[T.White]                            -0.085754    0.183383   \n",
      "C(officer_gender)[T.Male]                            0.153666    0.020337   \n",
      "C(officer_gender)[T.TGNC / Other]                    0.215031    0.267978   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Brooklyn]  -0.204044    0.015000   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Manhat...  -0.303968    0.016825   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Outsid...   0.084917    0.144278   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Queens]    -0.320044    0.018885   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Staten...  -0.347514    0.028880   \n",
      "C(Q('Location Type Of Incident'))[T.Bus]             0.127331    0.219388   \n",
      "C(Q('Location Type Of Incident'))[T.Commercial ...   0.505484    0.033153   \n",
      "C(Q('Location Type Of Incident'))[T.Hospital]       -0.455981    0.085738   \n",
      "C(Q('Location Type Of Incident'))[T.NYCHA]           0.294983    0.035879   \n",
      "C(Q('Location Type Of Incident'))[T.Other]           0.168582    0.054357   \n",
      "C(Q('Location Type Of Incident'))[T.Park]            0.611228    0.052973   \n",
      "C(Q('Location Type Of Incident'))[T.Phone]          -2.299420    0.468921   \n",
      "C(Q('Location Type Of Incident'))[T.Police buil...   0.082870    0.028348   \n",
      "C(Q('Location Type Of Incident'))[T.Police vehi...   0.474990    0.130355   \n",
      "C(Q('Location Type Of Incident'))[T.Public spac...   0.244254    0.049658   \n",
      "C(Q('Location Type Of Incident'))[T.Residential...   0.399221    0.027535   \n",
      "C(Q('Location Type Of Incident'))[T.River or wa...   0.010526    0.298333   \n",
      "C(Q('Location Type Of Incident'))[T.School]          0.641324    0.098725   \n",
      "C(Q('Location Type Of Incident'))[T.Street/high...   0.613866    0.015848   \n",
      "C(Q('Location Type Of Incident'))[T.Subway stat...   0.183263    0.033473   \n",
      "C(year)[T.1999.0]                                   10.943905  183.565527   \n",
      "C(year)[T.2000.0]                                   12.192671  183.565213   \n",
      "C(year)[T.2001.0]                                   12.235075  183.565212   \n",
      "\n",
      "                                                            z         P>|z|  \\\n",
      "Intercept                                           -0.076096  9.393429e-01   \n",
      "C(officer_race)[T.Asian]                            -0.851488  3.944981e-01   \n",
      "C(officer_race)[T.Black]                            -0.683926  4.940221e-01   \n",
      "C(officer_race)[T.Hispanic]                         -0.291839  7.704098e-01   \n",
      "C(officer_race)[T.White]                            -0.467623  6.400544e-01   \n",
      "C(officer_gender)[T.Male]                            7.555929  4.158814e-14   \n",
      "C(officer_gender)[T.TGNC / Other]                    0.802420  4.223101e-01   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Brooklyn] -13.603256  3.829972e-42   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Manhat... -18.066322  5.869911e-73   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Outsid...   0.588564  5.561538e-01   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Queens]   -16.947303  2.014876e-64   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Staten... -12.033164  2.378668e-33   \n",
      "C(Q('Location Type Of Incident'))[T.Bus]             0.580393  5.616499e-01   \n",
      "C(Q('Location Type Of Incident'))[T.Commercial ...  15.246825  1.728357e-52   \n",
      "C(Q('Location Type Of Incident'))[T.Hospital]       -5.318335  1.047210e-07   \n",
      "C(Q('Location Type Of Incident'))[T.NYCHA]           8.221696  2.006454e-16   \n",
      "C(Q('Location Type Of Incident'))[T.Other]           3.101388  1.926158e-03   \n",
      "C(Q('Location Type Of Incident'))[T.Park]           11.538456  8.442706e-31   \n",
      "C(Q('Location Type Of Incident'))[T.Phone]          -4.903645  9.407422e-07   \n",
      "C(Q('Location Type Of Incident'))[T.Police buil...   2.923277  3.463680e-03   \n",
      "C(Q('Location Type Of Incident'))[T.Police vehi...   3.643814  2.686277e-04   \n",
      "C(Q('Location Type Of Incident'))[T.Public spac...   4.918748  8.709937e-07   \n",
      "C(Q('Location Type Of Incident'))[T.Residential...  14.498866  1.231675e-47   \n",
      "C(Q('Location Type Of Incident'))[T.River or wa...   0.035282  9.718550e-01   \n",
      "C(Q('Location Type Of Incident'))[T.School]          6.496051  8.245583e-11   \n",
      "C(Q('Location Type Of Incident'))[T.Street/high...  38.733650  0.000000e+00   \n",
      "C(Q('Location Type Of Incident'))[T.Subway stat...   5.474944  4.376491e-08   \n",
      "C(year)[T.1999.0]                                    0.059619  9.524595e-01   \n",
      "C(year)[T.2000.0]                                    0.066421  9.470423e-01   \n",
      "C(year)[T.2001.0]                                    0.066652  9.468584e-01   \n",
      "\n",
      "                                                        [0.025      0.975]  \n",
      "Intercept                                          -373.749915  345.812844  \n",
      "C(officer_race)[T.Asian]                             -0.519562    0.204849  \n",
      "C(officer_race)[T.Black]                             -0.486038    0.234580  \n",
      "C(officer_race)[T.Hispanic]                          -0.413394    0.306240  \n",
      "C(officer_race)[T.White]                             -0.445178    0.273670  \n",
      "C(officer_gender)[T.Male]                             0.113806    0.193526  \n",
      "C(officer_gender)[T.TGNC / Other]                    -0.310197    0.740259  \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Brooklyn]   -0.233442   -0.174645  \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Manhat...   -0.336944   -0.270991  \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Outsid...   -0.197862    0.367696  \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Queens]     -0.357058   -0.283031  \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Staten...   -0.404117   -0.290911  \n",
      "C(Q('Location Type Of Incident'))[T.Bus]             -0.302661    0.557323  \n",
      "C(Q('Location Type Of Incident'))[T.Commercial ...    0.440505    0.570464  \n",
      "C(Q('Location Type Of Incident'))[T.Hospital]        -0.624023   -0.287938  \n",
      "C(Q('Location Type Of Incident'))[T.NYCHA]            0.224662    0.365304  \n",
      "C(Q('Location Type Of Incident'))[T.Other]            0.062044    0.275120  \n",
      "C(Q('Location Type Of Incident'))[T.Park]             0.507403    0.715054  \n",
      "C(Q('Location Type Of Incident'))[T.Phone]           -3.218488   -1.380353  \n",
      "C(Q('Location Type Of Incident'))[T.Police buil...    0.027308    0.138431  \n",
      "C(Q('Location Type Of Incident'))[T.Police vehi...    0.219499    0.730482  \n",
      "C(Q('Location Type Of Incident'))[T.Public spac...    0.146926    0.341581  \n",
      "C(Q('Location Type Of Incident'))[T.Residential...    0.345254    0.453188  \n",
      "C(Q('Location Type Of Incident'))[T.River or wa...   -0.574196    0.595248  \n",
      "C(Q('Location Type Of Incident'))[T.School]           0.447826    0.834821  \n",
      "C(Q('Location Type Of Incident'))[T.Street/high...    0.582804    0.644928  \n",
      "C(Q('Location Type Of Incident'))[T.Subway stat...    0.117657    0.248868  \n",
      "C(year)[T.1999.0]                                  -348.837916  370.725726  \n",
      "C(year)[T.2000.0]                                  -347.588535  371.973877  \n",
      "C(year)[T.2001.0]                                  -347.546129  372.016279  \n",
      "\n",
      "Odds ratios for C(officer_race):\n",
      "                                   OR     OR_lo     OR_hi         p\n",
      "C(officer_race)[T.Asian]     0.854399  0.594781  1.227339  0.394498\n",
      "C(officer_race)[T.Black]     0.881854  0.615058  1.264377  0.494022\n",
      "C(officer_race)[T.White]     0.917820  0.640710  1.314781  0.640054\n",
      "C(officer_race)[T.Hispanic]  0.947833  0.661402  1.358308  0.770410\n",
      "\n",
      "Odds ratios for C(officer_gender):\n",
      "                                         OR     OR_lo     OR_hi             p\n",
      "C(officer_gender)[T.Male]          1.166102  1.120535  1.213522  4.158814e-14\n",
      "C(officer_gender)[T.TGNC / Other]  1.239901  0.733303  2.096479  4.223101e-01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Ensure context variables from Complaints are present\n",
    "KEY = \"Complaint Id\"\n",
    "need_cols = [\"Borough Of Incident Occurrence\", \"Location Type Of Incident\", \"Incident Date\"]\n",
    "missing = [c for c in need_cols if c not in decided.columns]\n",
    "if missing:\n",
    "    decided = decided.merge(complaints[[KEY] + need_cols], on=KEY, how=\"left\")\n",
    "\n",
    "#  Year\n",
    "decided[\"year\"] = pd.to_datetime(decided[\"Incident Date\"], errors=\"coerce\").dt.year\n",
    "\n",
    "#  Bring FADO Type if not already present\n",
    "if \"FADO Type\" not in decided.columns and \"FADO Type\" in allegations.columns:\n",
    "    # this introduces some noise. A stricter approach uses allegation-level keys.\n",
    "    decided = decided.merge(allegations[[KEY, \"FADO Type\"]].drop_duplicates(), on=KEY, how=\"left\")\n",
    "\n",
    "#  Keep rows with known protected attributes (to interpret coefficients cleanly)\n",
    "dfm = decided.copy()\n",
    "dfm = dfm[dfm[\"officer_race\"].notna() & dfm[\"officer_gender\"].notna()].copy()\n",
    "\n",
    "# Build formula with categorical encodings\n",
    "terms = [\n",
    "    \"C(officer_race)\",\n",
    "    \"C(officer_gender)\",\n",
    "    \"C(Q('Borough Of Incident Occurrence'))\",\n",
    "    \"C(Q('Location Type Of Incident'))\",\n",
    "    \"C(year)\"\n",
    "]\n",
    "if \"FADO Type\" in dfm.columns:\n",
    "    terms.append(\"C(Q('FADO Type'))\")\n",
    "\n",
    "formula = \"outcome_bin ~ \" + \" + \".join(terms)\n",
    "\n",
    "#  Design matrices and fit\n",
    "y, X = pt.dmatrices(formula, data=dfm, return_type=\"dataframe\")\n",
    "logit = sm.Logit(y, X).fit(disp=False)\n",
    "\n",
    "print(\"\\nAdjusted logistic regression: odds on substantiation\")\n",
    "print(logit.summary2().tables[1].head(30))  # top rows\n",
    "\n",
    "#  Handy helper to print exponentiated coefficients (odds ratios) for protected terms\n",
    "def print_or(prefix=\"C(officer_race)\"):\n",
    "    coefs = logit.params.filter(like=prefix)\n",
    "    conf  = logit.conf_int().loc[coefs.index]\n",
    "    OR    = np.exp(coefs)\n",
    "    OR_lo = np.exp(conf[0])\n",
    "    OR_hi = np.exp(conf[1])\n",
    "    out = pd.DataFrame({\"OR\": OR, \"OR_lo\": OR_lo, \"OR_hi\": OR_hi, \"p\": logit.pvalues.loc[coefs.index]})\n",
    "    # Sort by absolute log-odds (magnitude)\n",
    "    print(f\"\\nOdds ratios for {prefix}:\")\n",
    "    print(out.sort_values(\"OR\"))\n",
    "\n",
    "print_or(\"C(officer_race)\")\n",
    "print_or(\"C(officer_gender)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04dd2815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "By officer race within FADO = Abuse of Authority\n",
      "    officer_race_f      rate      n    ci_low   ci_high\n",
      "0            White  0.342474  53350  0.338459  0.346512\n",
      "1         Hispanic  0.406062  29163  0.400439  0.411711\n",
      "2            Black  0.355903  14917  0.348257  0.363622\n",
      "3            Asian  0.431266   5354  0.418054  0.444577\n",
      "4  American Indian  0.270270    111  0.196369  0.359540\n",
      "\n",
      "By officer race within FADO = Force\n",
      "    officer_race_f      rate      n    ci_low   ci_high\n",
      "0            White  0.210734  25136  0.205736  0.215819\n",
      "1         Hispanic  0.257708  13589  0.250424  0.265130\n",
      "2            Black  0.224953   7406  0.215587  0.234604\n",
      "3            Asian  0.299528   2544  0.282042  0.317619\n",
      "4  American Indian  0.209302     43  0.114228  0.352056\n",
      "\n",
      "By officer race within FADO = Discourtesy\n",
      "    officer_race_f      rate      n    ci_low   ci_high\n",
      "0            White  0.269025  14218  0.261799  0.276376\n",
      "1         Hispanic  0.301247   7137  0.290712  0.311996\n",
      "2            Black  0.256059   3796  0.242426  0.270185\n",
      "3            Asian  0.351648   1092  0.323893  0.380444\n",
      "4  American Indian  0.206897     29  0.098461  0.383901\n",
      "\n",
      "By officer race within FADO = Offensive Language\n",
      "    officer_race_f      rate     n    ci_low   ci_high\n",
      "0            White  0.248731  2561  0.232374  0.265841\n",
      "1         Hispanic  0.307939  1247  0.282939  0.334119\n",
      "2            Black  0.253478   647  0.221481  0.288384\n",
      "3            Asian  0.323529   204  0.263107  0.390476\n",
      "4  American Indian  0.000000     4  0.000000  0.489891\n",
      "\n",
      "By officer race within period = 2021-25\n",
      "    officer_race_f      rate      n    ci_low   ci_high\n",
      "0            White  0.580521  16685  0.573016  0.587990\n",
      "1         Hispanic  0.600864  13890  0.592693  0.608979\n",
      "2            Black  0.545049   6282  0.532712  0.557332\n",
      "3            Asian  0.541151   3718  0.525100  0.557118\n",
      "4  American Indian  0.777778     18  0.547854  0.909991\n",
      "\n",
      "By officer race within period = 2006-10\n",
      "    officer_race_f      rate      n    ci_low   ci_high\n",
      "0            White  0.122020  20431  0.117603  0.126580\n",
      "1         Hispanic  0.138830  10783  0.132432  0.145485\n",
      "2            Black  0.125734   6132  0.117669  0.134267\n",
      "3            Asian  0.144543   1356  0.126830  0.164264\n",
      "4  American Indian  0.019231     52  0.003403  0.101205\n",
      "\n",
      "By officer race within period = 2011-15\n",
      "    officer_race_f      rate      n    ci_low   ci_high\n",
      "0            White  0.280425  14478  0.273167  0.287800\n",
      "1         Hispanic  0.274523   7595  0.264602  0.284671\n",
      "2            Black  0.251496   4346  0.238820  0.264611\n",
      "3            Asian  0.247885   1182  0.224113  0.273291\n",
      "4  American Indian  0.222222     27  0.106072  0.407569\n",
      "\n",
      "By officer race within period = 2016-20\n",
      "    officer_race_f      rate      n    ci_low   ci_high\n",
      "0            White  0.424446  17418  0.417123  0.431802\n",
      "1         Hispanic  0.441681  10091  0.432016  0.451390\n",
      "2            Black  0.417092   4505  0.402770  0.431555\n",
      "3            Asian  0.432151   2115  0.411181  0.453367\n",
      "4  American Indian  0.291667     24  0.149146  0.491677\n",
      "\n",
      "By officer race within period = 2000-05\n",
      "    officer_race_f      rate      n    ci_low   ci_high\n",
      "0            White  0.171626  26010  0.167093  0.176257\n",
      "1         Hispanic  0.177760   8714  0.169875  0.185928\n",
      "2            Black  0.180307   5474  0.170348  0.190714\n",
      "3            Asian  0.153477    834  0.130608  0.179524\n",
      "4  American Indian  0.257576     66  0.167488  0.374331\n"
     ]
    }
   ],
   "source": [
    "def rates_with_ci(frame: pd.DataFrame, group_col: str) -> pd.DataFrame:\n",
    "    t = (frame.groupby(group_col, dropna=False)[\"outcome_bin\"]\n",
    "         .agg(rate=\"mean\", n=\"count\")\n",
    "         .sort_values(\"n\", ascending=False)\n",
    "         .reset_index())\n",
    "    ci_low, ci_high = proportion_confint(\n",
    "        count=(t[\"rate\"]*t[\"n\"]).round().astype(int),\n",
    "        nobs=t[\"n\"], method=\"wilson\"\n",
    "    )\n",
    "    t[\"ci_low\"]  = ci_low\n",
    "    t[\"ci_high\"] = ci_high\n",
    "    return t\n",
    "\n",
    "# Ensure FADO Type present\n",
    "if \"FADO Type\" not in decided.columns and \"FADO Type\" in allegations.columns:\n",
    "    decided = decided.merge(\n",
    "        allegations[[\"Complaint Id\",\"FADO Type\"]].drop_duplicates(),\n",
    "        on=\"Complaint Id\", how=\"left\"\n",
    "    )\n",
    "\n",
    "# Period buckets if not already present\n",
    "if \"year\" not in decided.columns:\n",
    "    decided[\"year\"] = pd.to_datetime(decided[\"Incident Date\"], errors=\"coerce\").dt.year\n",
    "decided[\"period\"] = pd.cut(decided[\"year\"],\n",
    "                           bins=[1999,2005,2010,2015,2020,2026],\n",
    "                           labels=[\"2000-05\",\"2006-10\",\"2011-15\",\"2016-20\",\"2021-25\"])\n",
    "\n",
    "# 9a) By FADO type, race differences\n",
    "if \"FADO Type\" in decided.columns:\n",
    "    top_fado = decided[\"FADO Type\"].value_counts(dropna=True).index[:4]\n",
    "    for f in top_fado:\n",
    "        sub = decided[(decided[\"FADO Type\"] == f) & (decided[\"officer_race\"].notna())].copy()\n",
    "        sub[\"officer_race_f\"] = sub[\"officer_race\"]\n",
    "        tab = rates_with_ci(sub, \"officer_race_f\")\n",
    "        print(f\"\\nBy officer race within FADO = {f}\")\n",
    "        print(tab)\n",
    "\n",
    "# 9b) By time period, race differences\n",
    "for p in decided[\"period\"].dropna().unique():\n",
    "    sub = decided[(decided[\"period\"] == p) & (decided[\"officer_race\"].notna())].copy()\n",
    "    sub[\"officer_race_f\"] = sub[\"officer_race\"]\n",
    "    tab = rates_with_ci(sub, \"officer_race_f\")\n",
    "    print(f\"\\nBy officer race within period = {p}\")\n",
    "    print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29f886b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sensitivity] Decided excluding UTD shape: (205487, 23)\n",
      "[Sensitivity] Overall substantiation rate: 0.303\n"
     ]
    }
   ],
   "source": [
    "def _norm(s): return \"\" if pd.isna(s) else str(s).strip()\n",
    "def is_utd(s): return _norm(s) == \"Unable to Determine\"\n",
    "\n",
    "mask_valid   = allegations[\"ccrb_valid\"]\n",
    "mask_invalid = allegations[\"ccrb_invalid\"] & ~allegations[\"CCRB Complaint Disposition\"].map(is_utd)\n",
    "\n",
    "decided_exclUTD = allegations[mask_valid | mask_invalid].copy()\n",
    "decided_exclUTD[\"outcome_bin\"] = decided_exclUTD[\"ccrb_valid\"].astype(int)\n",
    "\n",
    "print(\"\\n[Sensitivity] Decided excluding UTD shape:\", decided_exclUTD.shape)\n",
    "print(\"[Sensitivity] Overall substantiation rate:\", round(decided_exclUTD[\"outcome_bin\"].mean(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf14054d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary  ---\n",
      "Among decided allegations (n=213,737), the substantiation rate is 29.1 percent.\n",
      "Unadjusted, substantiation rates differ by officer race (e.g., reference ≈ White: 29.5 percent; Hispanic: 35.0 percent; Black: 30.4 percent).\n",
      "After adjusting for borough, location type, year, and FADO type in a logistic model, officer-race coefficients are not statistically significant, while male officers show modestly higher odds of substantiation.\n",
      "Stratified checks by FADO type and by period show the same qualitative pattern. A sensitivity analysis excluding 'Unable to Determine' leaves the headline conclusions unchanged.\n"
     ]
    }
   ],
   "source": [
    "overall_rate = decided[\"outcome_bin\"].mean()*100\n",
    "race_tab = by_race_known.sort_values(\"n\", ascending=False)\n",
    "gender_tab = by_gender_known.sort_values(\"n\", ascending=False)\n",
    "\n",
    "print(\"\\n--- Summary  ---\")\n",
    "print(f\"Among decided allegations (n={len(decided):,}), the substantiation rate is {overall_rate:.1f} percent.\")\n",
    "print(\"Unadjusted, substantiation rates differ by officer race (e.g., reference ≈ \"\n",
    "      f\"{race_tab.iloc[0]['officer_race_f']}: {race_tab.iloc[0]['rate']*100:.1f} percent; \"\n",
    "      f\"{race_tab.iloc[1]['officer_race_f']}: {race_tab.iloc[1]['rate']*100:.1f} percent; \"\n",
    "      f\"{race_tab.iloc[2]['officer_race_f']}: {race_tab.iloc[2]['rate']*100:.1f} percent).\")\n",
    "print(\"After adjusting for borough, location type, year, and FADO type in a logistic model, \"\n",
    "      \"officer-race coefficients are not statistically significant, while male officers show modestly higher odds of substantiation.\")\n",
    "print(\"Stratified checks by FADO type and by period show the same qualitative pattern. \"\n",
    "      \"A sensitivity analysis excluding 'Unable to Determine' leaves the headline conclusions unchanged.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285ce3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CCRB fairness audit summary ===\n",
      "Among decided allegations (n=213,737), the substantiation rate is 29.1%.\n",
      "Sensitivity excluding 'Unable to Determine' yields 30.3%.\n",
      "Unadjusted by officer race: White 29.5% (+0.0 pp vs White); Hispanic 35.0% (+5.6 pp vs White); Black 30.4% (+0.9 pp vs White); Asian 38.4% (+9.0 pp vs White).\n",
      "Unadjusted by officer gender: Male 31.6%; Female 31.5%.\n",
      "Adjusted logistic regression with controls (borough, location type, year, FADO) shows no statistically significant officer-race effects,\n",
      "while male officers have modestly higher odds of substantiation. Context terms are strong.\n",
      "Interpretation per Equal Opportunity: report raw TPR gaps and the adjusted view, stratify by FADO and period,\n",
      "and keep calibration-by-group and EO monitoring as guardrails.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def fmt_pct(x): \n",
    "    return f\"{100*x:.1f}%\"\n",
    "\n",
    "overall = decided[\"outcome_bin\"].mean()\n",
    "sens_overall = 0.303 \n",
    "\n",
    "race_sorted = by_race_known.sort_values(\"n\", ascending=False).reset_index(drop=True).copy()\n",
    "gender_sorted = by_gender_known.sort_values(\"n\", ascending=False).reset_index(drop=True).copy()\n",
    "\n",
    "# Reference group for race disparities (largest-N)\n",
    "ref_row = race_sorted.loc[0]\n",
    "ref_group = ref_row[\"officer_race_f\"]\n",
    "ref_rate  = ref_row[\"rate\"]\n",
    "\n",
    "# Build a compact sentence for top 4 race groups\n",
    "race_bits = []\n",
    "for i in range(min(4, len(race_sorted))):\n",
    "    g = race_sorted.loc[i, \"officer_race_f\"]\n",
    "    r = race_sorted.loc[i, \"rate\"]\n",
    "    diff = r - ref_rate\n",
    "    sign = \"+\" if diff >= 0 else \"−\"\n",
    "    race_bits.append(f\"{g} {fmt_pct(r)} ({sign}{abs(diff)*100:.1f} pp vs {ref_group})\")\n",
    "race_sentence = \"; \".join(race_bits)\n",
    "\n",
    "# Gender sentence for the main two groups if present\n",
    "gender_bits = []\n",
    "for g in [\"Male\", \"Female\"]:\n",
    "    row = gender_sorted[gender_sorted[\"officer_gender_f\"] == g]\n",
    "    if len(row):\n",
    "        gender_bits.append(f\"{g} {fmt_pct(row.iloc[0]['rate'])}\")\n",
    "gender_sentence = \"; \".join(gender_bits) if gender_bits else \"Gender rates printed above\"\n",
    "\n",
    "print(\"=== CCRB fairness audit summary ===\")\n",
    "print(f\"Among decided allegations (n={len(decided):,}), the substantiation rate is {fmt_pct(overall)}.\")\n",
    "print(f\"Sensitivity excluding 'Unable to Determine' yields {fmt_pct(sens_overall)}.\")\n",
    "print(f\"Unadjusted by officer race: {race_sentence}.\")\n",
    "print(f\"Unadjusted by officer gender: {gender_sentence}.\")\n",
    "print(\"Adjusted logistic regression with controls (borough, location type, year, FADO) shows no statistically significant officer-race effects,\")\n",
    "print(\"while male officers have modestly higher odds of substantiation. Context terms are strong.\")\n",
    "print(\"Interpretation per Equal Opportunity: report raw TPR gaps and the adjusted view, stratify by FADO and period,\")\n",
    "print(\"and keep calibration-by-group and EO monitoring as guardrails.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784fae41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ef4e60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substantiated allegations: 62,269\n",
      "With any penalty field present: 37564\n",
      "\n",
      "Any-penalty rate by officer race (substantiated):\n",
      "    officer_race_f      rate      n        ci_low   ci_high\n",
      "0            White  0.662991  28115  6.574441e-01  0.668494\n",
      "1         Hispanic  0.671515  17943  6.646072e-01  0.678350\n",
      "2            Black  0.681055   8155  6.708559e-01  0.691083\n",
      "3          Unknown  0.000000   4468  5.421011e-20  0.000859\n",
      "4            Asian  0.654530   3543  6.387124e-01  0.670013\n",
      "5  American Indian  0.822222     45  6.867018e-01  0.907056\n",
      "\n",
      "Any-penalty rate by officer gender (substantiated):\n",
      "  officer_gender_f      rate      n    ci_low   ci_high\n",
      "0             Male  0.670807  52817  0.666787  0.674802\n",
      "1           Female  0.635149   4939  0.621623  0.648464\n",
      "2          Unknown  0.002897   4487  0.001694  0.004951\n",
      "3     TGNC / Other  0.730769     26  0.539170  0.862956\n",
      "\n",
      "Penalty severity (mean) by officer race:\n",
      "    officer_race_f      n  mean_sev     p_any\n",
      "5            White  28115  0.360733  0.662991\n",
      "3         Hispanic  17943  0.342083  0.671515\n",
      "2            Black   8155  0.357695  0.681055\n",
      "4          Unknown   4468  0.000000  0.000000\n",
      "1            Asian   3543  0.366638  0.654530\n",
      "0  American Indian     45  0.333333  0.822222\n",
      "\n",
      "Penalty severity (mean) by officer gender:\n",
      "  officer_gender_f      n  mean_sev     p_any\n",
      "1             Male  52817  0.354318  0.670807\n",
      "0           Female   4939  0.359587  0.635149\n",
      "3          Unknown   4487  0.000891  0.002897\n",
      "2     TGNC / Other     26  0.653846  0.730769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\souq_e_commerce_3_11\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Clean fit] Logit for any_penalty:\n",
      "                                                        Coef.       Std.Err.  \\\n",
      "Intercept                                          -25.070243  124867.110183   \n",
      "C(officer_race)[T.Asian]                            -0.909029       0.406305   \n",
      "C(officer_race)[T.Black]                            -0.827664       0.405419   \n",
      "C(officer_race)[T.Hispanic]                         -0.856330       0.405014   \n",
      "C(officer_race)[T.White]                            -0.900294       0.404772   \n",
      "C(officer_gender)[T.Male]                            0.217459       0.032862   \n",
      "C(officer_gender)[T.TGNC / Other]                    0.224594       0.452614   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Brooklyn]   0.013504       0.024193   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Manhat...   0.093081       0.028060   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Outsid...  -0.225199       0.240070   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Queens]     0.042569       0.031662   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Staten...  -0.211276       0.048495   \n",
      "C(Q('Location Type Of Incident'))[T.Bus]             1.201879       0.496534   \n",
      "C(Q('Location Type Of Incident'))[T.Commercial ...   0.333317       0.054846   \n",
      "C(Q('Location Type Of Incident'))[T.Hospital]        0.290311       0.159844   \n",
      "C(Q('Location Type Of Incident'))[T.NYCHA]          -0.088112       0.054149   \n",
      "C(Q('Location Type Of Incident'))[T.Other]           0.169307       0.096579   \n",
      "C(Q('Location Type Of Incident'))[T.Park]            0.136193       0.090362   \n",
      "C(Q('Location Type Of Incident'))[T.Phone]          -1.884619       1.135013   \n",
      "C(Q('Location Type Of Incident'))[T.Police buil...  -0.086733       0.046871   \n",
      "C(Q('Location Type Of Incident'))[T.Police vehi...  -0.824106       0.204332   \n",
      "C(Q('Location Type Of Incident'))[T.Public spac...   0.457106       0.091242   \n",
      "C(Q('Location Type Of Incident'))[T.Residential...   0.089754       0.046401   \n",
      "C(Q('Location Type Of Incident'))[T.River or wa...   0.490914       0.596071   \n",
      "C(Q('Location Type Of Incident'))[T.School]          0.055579       0.153051   \n",
      "C(Q('Location Type Of Incident'))[T.Street/high...   0.205633       0.027086   \n",
      "C(Q('Location Type Of Incident'))[T.Subway stat...   0.397633       0.058265   \n",
      "C(year)[T.2000.0]                                   23.972565  124867.110182   \n",
      "C(year)[T.2001.0]                                   25.407600  124867.110182   \n",
      "C(year)[T.2002.0]                                   26.761208  124867.110182   \n",
      "\n",
      "                                                           z         P>|z|  \\\n",
      "Intercept                                          -0.000201  9.998398e-01   \n",
      "C(officer_race)[T.Asian]                           -2.237304  2.526651e-02   \n",
      "C(officer_race)[T.Black]                           -2.041504  4.120072e-02   \n",
      "C(officer_race)[T.Hispanic]                        -2.114321  3.448789e-02   \n",
      "C(officer_race)[T.White]                           -2.224202  2.613483e-02   \n",
      "C(officer_gender)[T.Male]                           6.617432  3.654921e-11   \n",
      "C(officer_gender)[T.TGNC / Other]                   0.496216  6.197419e-01   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Brooklyn]  0.558184  5.767185e-01   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Manhat...  3.317267  9.090260e-04   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Outsid... -0.938055  3.482160e-01   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Queens]    1.344491  1.787898e-01   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Staten... -4.356641  1.320734e-05   \n",
      "C(Q('Location Type Of Incident'))[T.Bus]            2.420540  1.549746e-02   \n",
      "C(Q('Location Type Of Incident'))[T.Commercial ...  6.077309  1.222161e-09   \n",
      "C(Q('Location Type Of Incident'))[T.Hospital]       1.816218  6.933691e-02   \n",
      "C(Q('Location Type Of Incident'))[T.NYCHA]         -1.627226  1.036892e-01   \n",
      "C(Q('Location Type Of Incident'))[T.Other]          1.753049  7.959352e-02   \n",
      "C(Q('Location Type Of Incident'))[T.Park]           1.507192  1.317614e-01   \n",
      "C(Q('Location Type Of Incident'))[T.Phone]         -1.660439  9.682624e-02   \n",
      "C(Q('Location Type Of Incident'))[T.Police buil... -1.850445  6.424947e-02   \n",
      "C(Q('Location Type Of Incident'))[T.Police vehi... -4.033181  5.502680e-05   \n",
      "C(Q('Location Type Of Incident'))[T.Public spac...  5.009848  5.447313e-07   \n",
      "C(Q('Location Type Of Incident'))[T.Residential...  1.934314  5.307451e-02   \n",
      "C(Q('Location Type Of Incident'))[T.River or wa...  0.823583  4.101763e-01   \n",
      "C(Q('Location Type Of Incident'))[T.School]         0.363137  7.165028e-01   \n",
      "C(Q('Location Type Of Incident'))[T.Street/high...  7.591913  3.152170e-14   \n",
      "C(Q('Location Type Of Incident'))[T.Subway stat...  6.824504  8.822946e-12   \n",
      "C(year)[T.2000.0]                                   0.000192  9.998468e-01   \n",
      "C(year)[T.2001.0]                                   0.000203  9.998376e-01   \n",
      "C(year)[T.2002.0]                                   0.000214  9.998290e-01   \n",
      "\n",
      "                                                           [0.025  \\\n",
      "Intercept                                          -244760.109055   \n",
      "C(officer_race)[T.Asian]                                -1.705373   \n",
      "C(officer_race)[T.Black]                                -1.622270   \n",
      "C(officer_race)[T.Hispanic]                             -1.650144   \n",
      "C(officer_race)[T.White]                                -1.693633   \n",
      "C(officer_gender)[T.Male]                                0.153052   \n",
      "C(officer_gender)[T.TGNC / Other]                       -0.662512   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Brooklyn]      -0.033913   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Manhat...       0.038086   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Outsid...      -0.695727   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Queens]        -0.019487   \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Staten...      -0.306325   \n",
      "C(Q('Location Type Of Incident'))[T.Bus]                 0.228692   \n",
      "C(Q('Location Type Of Incident'))[T.Commercial ...       0.225820   \n",
      "C(Q('Location Type Of Incident'))[T.Hospital]           -0.022977   \n",
      "C(Q('Location Type Of Incident'))[T.NYCHA]              -0.194242   \n",
      "C(Q('Location Type Of Incident'))[T.Other]              -0.019984   \n",
      "C(Q('Location Type Of Incident'))[T.Park]               -0.040913   \n",
      "C(Q('Location Type Of Incident'))[T.Phone]              -4.109204   \n",
      "C(Q('Location Type Of Incident'))[T.Police buil...      -0.178598   \n",
      "C(Q('Location Type Of Incident'))[T.Police vehi...      -1.224588   \n",
      "C(Q('Location Type Of Incident'))[T.Public spac...       0.278276   \n",
      "C(Q('Location Type Of Incident'))[T.Residential...      -0.001190   \n",
      "C(Q('Location Type Of Incident'))[T.River or wa...      -0.677363   \n",
      "C(Q('Location Type Of Incident'))[T.School]             -0.244396   \n",
      "C(Q('Location Type Of Incident'))[T.Street/high...       0.152546   \n",
      "C(Q('Location Type Of Incident'))[T.Subway stat...       0.283435   \n",
      "C(year)[T.2000.0]                                  -244711.066246   \n",
      "C(year)[T.2001.0]                                  -244709.631211   \n",
      "C(year)[T.2002.0]                                  -244708.277603   \n",
      "\n",
      "                                                           0.975]  \n",
      "Intercept                                           244709.968570  \n",
      "C(officer_race)[T.Asian]                                -0.112685  \n",
      "C(officer_race)[T.Black]                                -0.033058  \n",
      "C(officer_race)[T.Hispanic]                             -0.062517  \n",
      "C(officer_race)[T.White]                                -0.106956  \n",
      "C(officer_gender)[T.Male]                                0.281867  \n",
      "C(officer_gender)[T.TGNC / Other]                        1.111701  \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Brooklyn]       0.060921  \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Manhat...       0.148077  \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Outsid...       0.245330  \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Queens]         0.104626  \n",
      "C(Q('Borough Of Incident Occurrence'))[T.Staten...      -0.116227  \n",
      "C(Q('Location Type Of Incident'))[T.Bus]                 2.175067  \n",
      "C(Q('Location Type Of Incident'))[T.Commercial ...       0.440813  \n",
      "C(Q('Location Type Of Incident'))[T.Hospital]            0.603599  \n",
      "C(Q('Location Type Of Incident'))[T.NYCHA]               0.018017  \n",
      "C(Q('Location Type Of Incident'))[T.Other]               0.358598  \n",
      "C(Q('Location Type Of Incident'))[T.Park]                0.313300  \n",
      "C(Q('Location Type Of Incident'))[T.Phone]               0.339965  \n",
      "C(Q('Location Type Of Incident'))[T.Police buil...       0.005133  \n",
      "C(Q('Location Type Of Incident'))[T.Police vehi...      -0.423624  \n",
      "C(Q('Location Type Of Incident'))[T.Public spac...       0.635937  \n",
      "C(Q('Location Type Of Incident'))[T.Residential...       0.180698  \n",
      "C(Q('Location Type Of Incident'))[T.River or wa...       1.659192  \n",
      "C(Q('Location Type Of Incident'))[T.School]              0.355553  \n",
      "C(Q('Location Type Of Incident'))[T.Street/high...       0.258720  \n",
      "C(Q('Location Type Of Incident'))[T.Subway stat...       0.511831  \n",
      "C(year)[T.2000.0]                                   244759.011376  \n",
      "C(year)[T.2001.0]                                   244760.446411  \n",
      "C(year)[T.2002.0]                                   244761.800019  \n",
      "\n",
      "OLS for penalty severity among those with a penalty:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       penalty_severity   R-squared:                       0.486\n",
      "Model:                            OLS   Adj. R-squared:                  0.483\n",
      "Method:                 Least Squares   F-statistic:                     194.4\n",
      "Date:                Mon, 27 Oct 2025   Prob (F-statistic):               0.00\n",
      "Time:                        20:57:43   Log-Likelihood:                -12972.\n",
      "No. Observations:               10964   AIC:                         2.605e+04\n",
      "Df Residuals:                   10910   BIC:                         2.645e+04\n",
      "Df Model:                          53                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================================================================\n",
      "                                                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                      0.8341      0.279      2.994      0.003       0.288       1.380\n",
      "C(officer_race)[T.Asian]                                      -0.0225      0.217     -0.104      0.917      -0.448       0.403\n",
      "C(officer_race)[T.Black]                                       0.0748      0.215      0.347      0.728      -0.347       0.497\n",
      "C(officer_race)[T.Hispanic]                                    0.0393      0.215      0.183      0.855      -0.382       0.461\n",
      "C(officer_race)[T.White]                                       0.0903      0.214      0.421      0.674      -0.330       0.511\n",
      "C(officer_gender)[T.Male]                                      0.0408      0.027      1.492      0.136      -0.013       0.094\n",
      "C(officer_gender)[T.TGNC / Other]                              1.8825      0.357      5.274      0.000       1.183       2.582\n",
      "C(Q('Borough Of Incident Occurrence'))[T.Brooklyn]             0.0157      0.021      0.762      0.446      -0.025       0.056\n",
      "C(Q('Borough Of Incident Occurrence'))[T.Manhattan]           -0.0732      0.023     -3.207      0.001      -0.118      -0.028\n",
      "C(Q('Borough Of Incident Occurrence'))[T.Outside NYC]          0.0366      0.194      0.189      0.850      -0.343       0.416\n",
      "C(Q('Borough Of Incident Occurrence'))[T.Queens]              -0.0934      0.026     -3.624      0.000      -0.144      -0.043\n",
      "C(Q('Borough Of Incident Occurrence'))[T.Staten Island]       -0.0234      0.038     -0.612      0.541      -0.098       0.052\n",
      "C(Q('Location Type Of Incident'))[T.Bus]                      -1.2822      0.562     -2.280      0.023      -2.385      -0.180\n",
      "C(Q('Location Type Of Incident'))[T.Commercial building]       0.0055      0.043      0.128      0.898      -0.079       0.090\n",
      "C(Q('Location Type Of Incident'))[T.Hospital]                 -0.4246      0.167     -2.539      0.011      -0.752      -0.097\n",
      "C(Q('Location Type Of Incident'))[T.NYCHA]                     0.1373      0.050      2.759      0.006       0.040       0.235\n",
      "C(Q('Location Type Of Incident'))[T.Other]                     0.1817      0.067      2.731      0.006       0.051       0.312\n",
      "C(Q('Location Type Of Incident'))[T.Park]                     -0.0096      0.068     -0.142      0.887      -0.142       0.123\n",
      "C(Q('Location Type Of Incident'))[T.Phone]                    -0.3119      0.793     -0.393      0.694      -1.867       1.243\n",
      "C(Q('Location Type Of Incident'))[T.Police building]          -0.2514      0.045     -5.629      0.000      -0.339      -0.164\n",
      "C(Q('Location Type Of Incident'))[T.Police vehicle]           -0.1545      0.195     -0.793      0.428      -0.536       0.227\n",
      "C(Q('Location Type Of Incident'))[T.Public space/building]     0.1754      0.074      2.361      0.018       0.030       0.321\n",
      "C(Q('Location Type Of Incident'))[T.Residential building]     -0.0490      0.037     -1.322      0.186      -0.122       0.024\n",
      "C(Q('Location Type Of Incident'))[T.School]                   -0.4208      0.200     -2.105      0.035      -0.813      -0.029\n",
      "C(Q('Location Type Of Incident'))[T.Street/highway]            0.0099      0.022      0.455      0.649      -0.033       0.052\n",
      "C(Q('Location Type Of Incident'))[T.Subway station/train]      0.1931      0.050      3.883      0.000       0.096       0.291\n",
      "C(year)[T.2001.0]                                             -0.0413      0.230     -0.180      0.857      -0.491       0.409\n",
      "C(year)[T.2002.0]                                              0.0293      0.183      0.160      0.873      -0.329       0.388\n",
      "C(year)[T.2003.0]                                              0.0161      0.179      0.090      0.928      -0.335       0.367\n",
      "C(year)[T.2004.0]                                              0.0241      0.177      0.136      0.891      -0.322       0.370\n",
      "C(year)[T.2005.0]                                              0.0466      0.177      0.263      0.792      -0.301       0.394\n",
      "C(year)[T.2006.0]                                              0.0378      0.181      0.209      0.835      -0.317       0.393\n",
      "C(year)[T.2007.0]                                              0.0103      0.184      0.056      0.955      -0.351       0.372\n",
      "C(year)[T.2008.0]                                              0.0350      0.182      0.193      0.847      -0.321       0.391\n",
      "C(year)[T.2009.0]                                              0.0472      0.178      0.265      0.791      -0.302       0.397\n",
      "C(year)[T.2010.0]                                              0.0428      0.178      0.240      0.810      -0.306       0.392\n",
      "C(year)[T.2011.0]                                              0.0914      0.178      0.513      0.608      -0.258       0.441\n",
      "C(year)[T.2012.0]                                              0.3602      0.180      2.004      0.045       0.008       0.713\n",
      "C(year)[T.2013.0]                                              0.5810      0.178      3.261      0.001       0.232       0.930\n",
      "C(year)[T.2014.0]                                              0.8611      0.178      4.847      0.000       0.513       1.209\n",
      "C(year)[T.2015.0]                                              0.9642      0.176      5.464      0.000       0.618       1.310\n",
      "C(year)[T.2016.0]                                              0.9264      0.176      5.253      0.000       0.581       1.272\n",
      "C(year)[T.2017.0]                                              0.8460      0.177      4.789      0.000       0.500       1.192\n",
      "C(year)[T.2018.0]                                              0.6652      0.176      3.783      0.000       0.321       1.010\n",
      "C(year)[T.2019.0]                                              0.9752      0.175      5.572      0.000       0.632       1.318\n",
      "C(year)[T.2020.0]                                              2.5706      0.178     14.422      0.000       2.221       2.920\n",
      "C(year)[T.2021.0]                                              2.2436      0.176     12.727      0.000       1.898       2.589\n",
      "C(year)[T.2022.0]                                              2.2326      0.177     12.628      0.000       1.886       2.579\n",
      "C(year)[T.2023.0]                                              1.4594      0.175      8.323      0.000       1.116       1.803\n",
      "C(year)[T.2024.0]                                              1.2762      0.181      7.033      0.000       0.920       1.632\n",
      "C(Q('FADO Type'))[T.Discourtesy]                               0.0924      0.023      4.020      0.000       0.047       0.137\n",
      "C(Q('FADO Type'))[T.Force]                                     0.2154      0.024      8.970      0.000       0.168       0.262\n",
      "C(Q('FADO Type'))[T.Offensive Language]                        0.3481      0.054      6.399      0.000       0.241       0.455\n",
      "C(Q('FADO Type'))[T.Untruthful Statement]                      1.1541      0.148      7.789      0.000       0.864       1.445\n",
      "==============================================================================\n",
      "Omnibus:                     2129.137   Durbin-Watson:                   2.009\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5733.542\n",
      "Skew:                           1.045   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.860   Cond. No.                         197.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Penalties fairness audit\n",
    "# Scope: only substantiated allegations\n",
    "# Goal: check any-penalty rate and penalty severity across officer race and gender,\n",
    "#       and fit a clean logistic model that is not distorted by \"Unknown\" coverage.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import patsy as pt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "# ---- 12.0 Guardrails: make sure we have the input frames ----\n",
    "# Expected: decided (from earlier steps), penalties, officers, allegations, complaints\n",
    "# decided must contain outcome_bin, officer_race, officer_gender, Complaint Id, Tax ID\n",
    "assert \"outcome_bin\" in decided.columns, \"decided must have outcome_bin\"\n",
    "assert penalties is not None, \"penalties DataFrame must be loaded\"\n",
    "\n",
    "# ---- 12.1 Keep only substantiated rows (this is our post-decision population) ----\n",
    "subst = decided[decided[\"outcome_bin\"] == 1].copy()\n",
    "print(f\"Substantiated allegations: {len(subst):,}\")\n",
    "\n",
    "# ---- 12.2 Choose penalty columns and join to substantiated rows ----\n",
    "# Note: names match the NYC Open Data schema at time of download\n",
    "pen_keep = [\n",
    "    \"Complaint Id\", \"Tax ID\",\n",
    "    \"NYPD Officer Penalty\",\n",
    "    \"APU CCRB Trial Recommended Penalty\",\n",
    "    \"APU Plea Agreed Penalty\",\n",
    "    \"APU Trial Commissioner Recommended Penalty\",\n",
    "    \"Non-APU NYPD Penalty Report Date\",\n",
    "]\n",
    "pen = penalties[[c for c in pen_keep if c in penalties.columns]].copy()\n",
    "\n",
    "subst_pen = (subst.merge(pen, on=[\"Complaint Id\",\"Tax ID\"], how=\"left\")\n",
    "                  .rename(columns={\"NYPD Officer Penalty\": \"final_penalty\"}))\n",
    "\n",
    "print(\"With any penalty field present:\", subst_pen[\"final_penalty\"].notna().sum())\n",
    "\n",
    "# ---- 12.3 Coalesce a single penalty_text column for display and analysis ----\n",
    "# Rationale: sometimes the NYPD final penalty is empty but APU recommendations exist.\n",
    "def coalesce_penalty(row):\n",
    "    for c in [\"final_penalty\",\n",
    "              \"APU Trial Commissioner Recommended Penalty\",\n",
    "              \"APU Plea Agreed Penalty\",\n",
    "              \"APU CCRB Trial Recommended Penalty\"]:\n",
    "        if c in row and pd.notna(row[c]) and str(row[c]).strip():\n",
    "            return str(row[c]).strip()\n",
    "    return np.nan\n",
    "\n",
    "subst_pen[\"penalty_text\"] = subst_pen.apply(coalesce_penalty, axis=1)\n",
    "\n",
    "# Binary indicator: any penalty recorded vs none recorded\n",
    "subst_pen[\"any_penalty\"] = subst_pen[\"penalty_text\"].notna().astype(int)\n",
    "\n",
    "# ---- 12.4 Simple ordered severity score for quick comparisons ----\n",
    "# This is a toy but monotone scale; higher means harsher.\n",
    "severity_order = [\n",
    "    \"Instructions\",\n",
    "    \"Formalized Training\",\n",
    "    \"Command Level Instructions\",\n",
    "    \"Command Discipline A\",\n",
    "    \"Command Discipline B\",\n",
    "    \"Charges\",\n",
    "    \"Termination\",\n",
    "]\n",
    "sev_map = {name.lower(): i+1 for i, name in enumerate(severity_order)}\n",
    "\n",
    "def severity_score(s):\n",
    "    if pd.isna(s):\n",
    "        return 0\n",
    "    key = str(s).strip().lower()\n",
    "    # exact or fuzzy contains\n",
    "    if key in sev_map:\n",
    "        return sev_map[key]\n",
    "    for name, rank in sev_map.items():\n",
    "        if name in key:\n",
    "            return rank\n",
    "    return 0\n",
    "\n",
    "subst_pen[\"penalty_severity\"] = subst_pen[\"penalty_text\"].map(severity_score)\n",
    "\n",
    "# Fill friendly buckets for protected attributes\n",
    "subst_pen[\"officer_race_f\"]   = subst_pen[\"officer_race\"].fillna(\"Unknown\")\n",
    "subst_pen[\"officer_gender_f\"] = subst_pen[\"officer_gender\"].fillna(\"Unknown\")\n",
    "\n",
    "# ---- 12.5 Any-penalty rates with Wilson 95% CIs by race and gender ----\n",
    "def rates_with_ci(frame: pd.DataFrame, group_col: str) -> pd.DataFrame:\n",
    "    t = (frame.groupby(group_col, dropna=False)[\"any_penalty\"]\n",
    "         .agg(rate=\"mean\", n=\"count\")\n",
    "         .sort_values(\"n\", ascending=False)\n",
    "         .reset_index())\n",
    "    lo, hi = proportion_confint((t[\"rate\"]*t[\"n\"]).round().astype(int),\n",
    "                                t[\"n\"], method=\"wilson\")\n",
    "    t[\"ci_low\"] = lo; t[\"ci_high\"] = hi\n",
    "    return t\n",
    "\n",
    "print(\"\\nAny-penalty rate by officer race (substantiated):\")\n",
    "print(rates_with_ci(subst_pen, \"officer_race_f\"))\n",
    "\n",
    "print(\"\\nAny-penalty rate by officer gender (substantiated):\")\n",
    "print(rates_with_ci(subst_pen, \"officer_gender_f\"))\n",
    "\n",
    "# ---- 12.6 Severity summaries by group ----\n",
    "def severity_summary(frame, group_col):\n",
    "    agg = (frame.groupby(group_col, dropna=False)\n",
    "           .agg(n=(\"penalty_severity\",\"size\"),\n",
    "                mean_sev=(\"penalty_severity\",\"mean\"),\n",
    "                p_any=(\"any_penalty\",\"mean\"))\n",
    "           .reset_index()\n",
    "           .sort_values(\"n\", ascending=False))\n",
    "    return agg\n",
    "\n",
    "print(\"\\nPenalty severity (mean) by officer race:\")\n",
    "print(severity_summary(subst_pen, \"officer_race_f\"))\n",
    "\n",
    "print(\"\\nPenalty severity (mean) by officer gender:\")\n",
    "print(severity_summary(subst_pen, \"officer_gender_f\"))\n",
    "\n",
    "# ---- 12.7 Build clean covariates for modeling any_penalty ----\n",
    "# We need context variables to avoid confusing data coverage with fairness signals.\n",
    "KEY = \"Complaint Id\"\n",
    "need_cols = [\"Borough Of Incident Occurrence\", \"Location Type Of Incident\", \"Incident Date\"]\n",
    "for c in need_cols:\n",
    "    if c not in subst_pen.columns and c in complaints.columns:\n",
    "        subst_pen = subst_pen.merge(complaints[[KEY, c]], on=KEY, how=\"left\")\n",
    "\n",
    "# Year and FADO Type\n",
    "subst_pen[\"year\"] = pd.to_datetime(subst_pen[\"Incident Date\"], errors=\"coerce\").dt.year\n",
    "if \"FADO Type\" not in subst_pen.columns and \"FADO Type\" in allegations.columns:\n",
    "    subst_pen = subst_pen.merge(\n",
    "        allegations[[KEY, \"FADO Type\"]].drop_duplicates(), on=KEY, how=\"left\"\n",
    "    )\n",
    "\n",
    "# ---- 12.8 Cleaned logistic model for any_penalty\n",
    "# Student note: \"Unknown\" buckets reflect missingness, not true zero punishment.\n",
    "# We model only rows where a penalty decision could be observed.\n",
    "dfp = subst_pen[\n",
    "    subst_pen[\"officer_race\"].notna() &\n",
    "    subst_pen[\"officer_gender\"].notna()\n",
    "].copy()\n",
    "\n",
    "# Optional stricter filter: only cases where a penalty could reasonably be recorded.\n",
    "# If your data has time-related coverage issues, uncomment the following line:\n",
    "# dfp = dfp[(dfp[\"year\"] >= 2014) | dfp[\"penalty_text\"].notna()].copy()\n",
    "\n",
    "terms = []\n",
    "if \"officer_race\" in dfp.columns:\n",
    "    terms.append(\"C(officer_race)\")\n",
    "if \"officer_gender\" in dfp.columns:\n",
    "    terms.append(\"C(officer_gender)\")\n",
    "if \"Borough Of Incident Occurrence\" in dfp.columns:\n",
    "    terms.append(\"C(Q('Borough Of Incident Occurrence'))\")\n",
    "if \"Location Type Of Incident\" in dfp.columns:\n",
    "    terms.append(\"C(Q('Location Type Of Incident'))\")\n",
    "if \"year\" in dfp.columns:\n",
    "    terms.append(\"C(year)\")\n",
    "if \"FADO Type\" in dfp.columns:\n",
    "    terms.append(\"C(Q('FADO Type'))\")\n",
    "\n",
    "if len(terms) >= 2:  # need at least protected + one control to be useful\n",
    "    formula = \"any_penalty ~ \" + \" + \".join(terms)\n",
    "    y, X = pt.dmatrices(formula, data=dfp, return_type=\"dataframe\")\n",
    "    try:\n",
    "        logit_pen_clean = sm.Logit(y, X).fit(disp=False)\n",
    "        print(\"\\n[Clean fit] Logit for any_penalty:\")\n",
    "        print(logit_pen_clean.summary2().tables[1].head(30))\n",
    "    except Exception as e:\n",
    "        print(\"Clean logit failed (separation or sparse cells):\", e)\n",
    "else:\n",
    "    print(\"Not enough covariates to fit a clean penalty model.\")\n",
    "\n",
    "# ---- 12.9 Optional: severity model for rows that received a penalty ----\n",
    "# Student note: separates the question \"was there any penalty\" from \"how harsh was it\".\n",
    "with_pen = subst_pen[subst_pen[\"penalty_severity\"] > 0].copy()\n",
    "if len(with_pen) > 100:  # avoid tiny-sample modeling\n",
    "    import statsmodels.formula.api as smf\n",
    "    sev_terms = []\n",
    "    if \"officer_race\" in with_pen.columns:\n",
    "        sev_terms.append(\"C(officer_race)\")\n",
    "    if \"officer_gender\" in with_pen.columns:\n",
    "        sev_terms.append(\"C(officer_gender)\")\n",
    "    if \"Borough Of Incident Occurrence\" in with_pen.columns:\n",
    "        sev_terms.append(\"C(Q('Borough Of Incident Occurrence'))\")\n",
    "    if \"Location Type Of Incident\" in with_pen.columns:\n",
    "        sev_terms.append(\"C(Q('Location Type Of Incident'))\")\n",
    "    if \"year\" in with_pen.columns:\n",
    "        sev_terms.append(\"C(year)\")\n",
    "    if \"FADO Type\" in with_pen.columns:\n",
    "        sev_terms.append(\"C(Q('FADO Type'))\")\n",
    "\n",
    "    if sev_terms:\n",
    "        sev_formula = \"penalty_severity ~ \" + \" + \".join(sev_terms)\n",
    "        sev_ols = smf.ols(sev_formula, data=with_pen).fit()\n",
    "        print(\"\\nOLS for penalty severity among those with a penalty:\")\n",
    "        print(sev_ols.summary())\n",
    "    else:\n",
    "        print(\"No covariates available for severity model.\")\n",
    "else:\n",
    "    print(\"Too few rows with non-zero severity to model reliably.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f1772c",
   "metadata": {},
   "source": [
    "Good thing is that Race and Gender have very few missing values combined And I dont think any imputations are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e6fac8",
   "metadata": {},
   "source": [
    "Wait, we cannot directly use the R code. In R those numbers were factor level indexes, not stable IDs. Factor orders can change between downloads. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "souq_e_commerce_3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
