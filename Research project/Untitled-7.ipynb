{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4502f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Any\n",
    "from itertools import product\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.sandbox.stats.runs import runstest_1samp\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import  gaussian_kde\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e26311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>weekday</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>VOL</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984-09-07</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0.10122</td>\n",
       "      <td>0.10122</td>\n",
       "      <td>97236149.0</td>\n",
       "      <td>0.10246</td>\n",
       "      <td>0.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0.10122</td>\n",
       "      <td>0.10062</td>\n",
       "      <td>75471114.0</td>\n",
       "      <td>0.10153</td>\n",
       "      <td>0.09878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1984-09-11</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0.10153</td>\n",
       "      <td>0.10246</td>\n",
       "      <td>177965367.0</td>\n",
       "      <td>0.10428</td>\n",
       "      <td>0.10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984-09-12</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.10246</td>\n",
       "      <td>0.09938</td>\n",
       "      <td>155467926.0</td>\n",
       "      <td>0.10306</td>\n",
       "      <td>0.09938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984-09-13</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0.10490</td>\n",
       "      <td>0.10490</td>\n",
       "      <td>242135546.0</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.10490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE    weekday     OPEN    CLOSE          VOL     HIGH      LOW\n",
       "0 1984-09-07     Friday  0.10122  0.10122   97236149.0  0.10246  0.10000\n",
       "1 1984-09-10     Monday  0.10122  0.10062   75471114.0  0.10153  0.09878\n",
       "2 1984-09-11    Tuesday  0.10153  0.10246  177965367.0  0.10428  0.10153\n",
       "3 1984-09-12  Wednesday  0.10246  0.09938  155467926.0  0.10306  0.09938\n",
       "4 1984-09-13   Thursday  0.10490  0.10490  242135546.0  0.10520  0.10490"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple = pd.read_csv(r\"D:\\data\\notebooks\\week-10\\cleaned_apple_high_low.csv\")\n",
    "apple['DATE'] = pd.to_datetime(apple['DATE'], errors='coerce')\n",
    "apple = apple.sort_values('DATE')\n",
    "apple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd57c6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FULL PIPELINE — ONE FUNCTION — RETURNS REPORT (NOT df_final)\n",
    "# Includes: inlined Support/Resistance + SR_Position feature\n",
    "# Removes: net% (not needed)\n",
    "# Keeps: subset logic + historical MC + future MC + report card EXACTLY like base\n",
    "# ============================================================\n",
    "\n",
    "from typing import Dict, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def full_strategy_pipeline(params: Dict[str, Any]) -> Dict[str, Any]:\n",
    "\n",
    "    df = params[\"df\"]\n",
    "\n",
    "    VALID_WEEKS       = params[\"VALID_WEEKS\"]\n",
    "    depth_grid        = params[\"depth_grid\"]\n",
    "    leaf_grid         = params[\"leaf_grid\"]\n",
    "    thresholds_tested = params[\"thresholds_tested\"]\n",
    "    FIXED             = params[\"FIXED\"]\n",
    "\n",
    "    alpha_p = params[\"alpha_p\"]\n",
    "    alpha_c = params[\"alpha_c\"]\n",
    "    p_min   = params[\"p_min\"]\n",
    "    c_min   = params[\"c_min\"]\n",
    "\n",
    "    n_trajectories = params[\"n_trajectories\"]\n",
    "    n_weeks        = params[\"n_weeks\"]\n",
    "    initial_bank   = params[\"initial_bank\"]\n",
    "    upper_thresh   = params[\"upper_thresh\"]\n",
    "    lower_thresh   = params[\"lower_thresh\"]\n",
    "    rng_seed       = params[\"rng_seed\"]\n",
    "\n",
    "    uniformity_binsize = params[\"uniformity_binsize\"]\n",
    "\n",
    "    cutoff_date       = params.get(\"cutoff_date\", None)\n",
    "    subset_start_date = params.get(\"subset_start_date\", None)\n",
    "    num_subsets       = params.get(\"num_subsets\", 3)\n",
    "\n",
    "    # Support/Resistance params (defaults match what you asked)\n",
    "    SR_SMOOTH_WINDOW = params.get(\"SR_SMOOTH_WINDOW\", 5)\n",
    "    SR_WINDOW_WEEKS  = params.get(\"SR_WINDOW_WEEKS\", 52)\n",
    "    ENVELOPE_A       = params.get(\"ENVELOPE_A\", 1.0)\n",
    "    ENVELOPE_B       = params.get(\"ENVELOPE_B\", 100.0)\n",
    "    SR_MAX_ITER      = params.get(\"SR_MAX_ITER\", 60)\n",
    "    SR_TOL           = params.get(\"SR_TOL\", 1e-9)\n",
    "\n",
    "    rng = np.random.default_rng(rng_seed)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Cleaning and Weekly Dataset (BASE, unchanged except net% removed)\n",
    "    # --------------------------------------------------------\n",
    "    df = df.sort_values(\"DATE\").reset_index(drop=True)\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
    "\n",
    "    if cutoff_date is not None:\n",
    "        cutoff_dt = pd.to_datetime(cutoff_date)\n",
    "        df = df[df[\"DATE\"] >= cutoff_dt].reset_index(drop=True)\n",
    "\n",
    "    # BASE normalizations kept (this is the SR feature version)\n",
    "    df[\"normalized_close\"] = (\n",
    "        (df[\"CLOSE\"] - df[\"CLOSE\"].expanding().mean().shift(1))\n",
    "        / df[\"CLOSE\"].expanding().std(ddof=0).shift(1)\n",
    "    )\n",
    "    df[\"normalized_open\"] = (\n",
    "        (df[\"OPEN\"] - df[\"OPEN\"].expanding().mean().shift(1))\n",
    "        / df[\"OPEN\"].expanding().std(ddof=0).shift(1)\n",
    "    )\n",
    "\n",
    "    df[\"weekday\"] = df[\"DATE\"].dt.weekday\n",
    "    df[\"week\"]    = df[\"DATE\"].dt.to_period(\"W-SUN\")\n",
    "\n",
    "    tue_open = (\n",
    "        df[df[\"weekday\"] == 1]\n",
    "        .groupby(\"week\")[\"OPEN\"]\n",
    "        .first()\n",
    "        .rename(\"tue_open\")\n",
    "    )\n",
    "    thu_open = (\n",
    "        df[df[\"weekday\"] == 3]\n",
    "        .groupby(\"week\")[\"OPEN\"]\n",
    "        .first()\n",
    "        .rename(\"thu_open\")\n",
    "    )\n",
    "\n",
    "    weekly = pd.concat([tue_open, thu_open], axis=1)\n",
    "    weekly[\"thu/tue\"] = weekly[\"thu_open\"] / weekly[\"tue_open\"]\n",
    "    weekly[\"week_type\"] = (weekly[\"thu/tue\"] > 1.0).astype(int)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # FULL SUPPORT / RESISTANCE (INLINED) + SR_Position\n",
    "    # --------------------------------------------------------\n",
    "    df_sr = df.copy()\n",
    "    df_sr[\"mid\"] = (df_sr[\"HIGH\"] + df_sr[\"LOW\"]) / 2.0\n",
    "\n",
    "    mon = df_sr[df_sr[\"DATE\"].dt.dayofweek == 0].copy().reset_index(drop=True)\n",
    "\n",
    "    mon[\"mid_smooth\"] = (\n",
    "        mon[\"mid\"]\n",
    "        .rolling(SR_SMOOTH_WINDOW, min_periods=SR_SMOOTH_WINDOW)\n",
    "        .mean()\n",
    "    )\n",
    "    mon = mon.dropna(subset=[\"mid_smooth\"]).reset_index(drop=True)\n",
    "\n",
    "    mon[\"t\"] = np.arange(len(mon), dtype=float)\n",
    "    t_all = mon[\"t\"].to_numpy()\n",
    "    y_all = mon[\"mid_smooth\"].to_numpy()\n",
    "\n",
    "    def fit_line(t, d, g, a_, b_):\n",
    "        X = np.column_stack([t, np.ones_like(t)])\n",
    "        m, c = np.linalg.lstsq(X, d, rcond=None)[0]\n",
    "\n",
    "        for _ in range(SR_MAX_ITER):\n",
    "            r = d - (m * t + c)\n",
    "            k = np.where(r > 0, a_, np.where(r < 0, b_, 0.0))\n",
    "            w = g * k\n",
    "\n",
    "            S_tt = np.sum(w * t * t)\n",
    "            S_t  = np.sum(w * t)\n",
    "            S_1  = np.sum(w)\n",
    "            R_t  = np.sum(w * t * d)\n",
    "            R_1  = np.sum(w * d)\n",
    "\n",
    "            A = np.array([[S_tt, S_t],\n",
    "                          [S_t,  S_1]])\n",
    "            B = np.array([R_t, R_1])\n",
    "\n",
    "            if abs(np.linalg.det(A)) < 1e-12:\n",
    "                break\n",
    "\n",
    "            m_new, c_new = np.linalg.solve(A, B)\n",
    "            if abs(m_new - m) + abs(c_new - c) < SR_TOL:\n",
    "                break\n",
    "\n",
    "            m, c = m_new, c_new\n",
    "\n",
    "        return float(m), float(c)\n",
    "\n",
    "    support_vals    = np.full(len(mon), np.nan)\n",
    "    resistance_vals = np.full(len(mon), np.nan)\n",
    "\n",
    "    for i in range(len(mon)):\n",
    "        T = t_all[i]\n",
    "        start = max(0, i - SR_WINDOW_WEEKS)\n",
    "        idx = slice(start, i + 1)\n",
    "\n",
    "        t_win = t_all[idx]\n",
    "        y_win = y_all[idx]\n",
    "\n",
    "        # base weighting as per your envelope code\n",
    "        g = (t_win - (T - SR_WINDOW_WEEKS)) / SR_WINDOW_WEEKS\n",
    "\n",
    "        # Support: (a,b) ; Resistance: swap (b,a)\n",
    "        m_s, c_s = fit_line(t_win, y_win, g, ENVELOPE_A, ENVELOPE_B)\n",
    "        m_r, c_r = fit_line(t_win, y_win, g, ENVELOPE_B, ENVELOPE_A)\n",
    "\n",
    "        support_vals[i]    = m_s * T + c_s\n",
    "        resistance_vals[i] = m_r * T + c_r\n",
    "\n",
    "    mon[\"support_envelope\"]    = support_vals\n",
    "    mon[\"resistance_envelope\"] = resistance_vals\n",
    "    mon[\"week\"] = mon[\"DATE\"].dt.to_period(\"W-SUN\")\n",
    "\n",
    "    sr = mon.set_index(\"week\")[[\"support_envelope\", \"resistance_envelope\"]]\n",
    "    weekly = weekly.join(sr, how=\"left\")\n",
    "\n",
    "    weekly[\"SR_Position\"] = (\n",
    "        (weekly[\"tue_open\"] - weekly[\"support_envelope\"])\n",
    "        / (weekly[\"resistance_envelope\"] - weekly[\"support_envelope\"])\n",
    "    )\n",
    "\n",
    "    weekly.loc[\n",
    "        (weekly[\"resistance_envelope\"] - weekly[\"support_envelope\"]) <= 0,\n",
    "        \"SR_Position\"\n",
    "    ] = np.nan\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Feature matrix (BASE features + SR_Position)\n",
    "    # --------------------------------------------------------\n",
    "    norm_tue_open = (\n",
    "        df[df[\"weekday\"] == 1]\n",
    "        .set_index(\"week\")[\"normalized_open\"]\n",
    "        .rename(\"Norm_Tue_Open\")\n",
    "    )\n",
    "    norm_prev_thu_open = (\n",
    "        df[df[\"weekday\"] == 3]\n",
    "        .set_index(\"week\")[\"normalized_open\"]\n",
    "        .rename(\"Norm_PrevThu_Open\")\n",
    "        .shift(1)\n",
    "    )\n",
    "    norm_prev_fri_open = (\n",
    "        df[df[\"weekday\"] == 4]\n",
    "        .set_index(\"week\")[\"normalized_open\"]\n",
    "        .rename(\"Norm_PrevFri_Open\")\n",
    "        .shift(1)\n",
    "    )\n",
    "\n",
    "    weekly_full = (\n",
    "        weekly.copy()\n",
    "        .join(norm_tue_open, how=\"left\")\n",
    "        .join(norm_prev_thu_open, how=\"left\")\n",
    "        .join(norm_prev_fri_open, how=\"left\")\n",
    "        .dropna()\n",
    "    )\n",
    "\n",
    "    features = [\"Norm_PrevThu_Open\", \"Norm_PrevFri_Open\", \"Norm_Tue_Open\", \"SR_Position\"]\n",
    "    target   = \"week_type\"\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Rolling Train–Validate–Test (BASE)\n",
    "    # --------------------------------------------------------\n",
    "    def precision(tp, fp):\n",
    "        return tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "\n",
    "    def chattiness(tp, fp, fn):\n",
    "        return (tp + fp) / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "\n",
    "    def model_score(tp, fp, fn):\n",
    "        P = precision(tp, fp)\n",
    "        C = chattiness(tp, fp, fn)\n",
    "        s = np.exp(alpha_p * (P - p_min) + alpha_c * (C - c_min))\n",
    "        return 0.0 if np.isnan(s) or np.isinf(s) else float(s)\n",
    "\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from itertools import product\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    TP = TN = FP = FN = 0\n",
    "    weekly_best = []\n",
    "\n",
    "    for t in tqdm(range(VALID_WEEKS + 1, len(weekly_full)), desc=\"Rolling simulation\"):\n",
    "\n",
    "        val_start = max(0, t - VALID_WEEKS)\n",
    "        training   = weekly_full.iloc[:val_start]\n",
    "        validation = weekly_full.iloc[val_start:t]\n",
    "        test       = weekly_full.iloc[[t]]\n",
    "\n",
    "        if len(training[target].unique()) < 2:\n",
    "            continue\n",
    "\n",
    "        train_X, train_y = training[features], training[target]\n",
    "        val_X, val_y     = validation[features], validation[target]\n",
    "        test_X, test_y   = test[features], test[target]\n",
    "\n",
    "        best_score  = -np.inf\n",
    "        best_params = None\n",
    "        best_model  = None\n",
    "\n",
    "        for depth, leaf in product(depth_grid, leaf_grid):\n",
    "            model = DecisionTreeClassifier(max_depth=depth, min_samples_leaf=leaf, **FIXED)\n",
    "            model.fit(train_X, train_y)\n",
    "            probs_val = model.predict_proba(val_X)[:, 1]\n",
    "\n",
    "            for thr in thresholds_tested:\n",
    "                preds_val = (probs_val > thr).astype(int)\n",
    "                tp = ((preds_val == 1) & (val_y == 1)).sum()\n",
    "                fp = ((preds_val == 1) & (val_y == 0)).sum()\n",
    "                fn = ((preds_val == 0) & (val_y == 1)).sum()\n",
    "                sc = model_score(tp, fp, fn)\n",
    "                if sc > best_score:\n",
    "                    best_score  = sc\n",
    "                    best_params = (depth, leaf, thr)\n",
    "                    best_model  = model\n",
    "\n",
    "        best_depth, best_leaf, best_thr = best_params\n",
    "\n",
    "        p_hat = best_model.predict_proba(test_X)[0, 1]\n",
    "        pred  = int(p_hat > best_thr)\n",
    "        true  = int(test_y.iloc[0])\n",
    "\n",
    "        if pred == 1 and true == 1:\n",
    "            TP += 1; outcome = \"TP\"\n",
    "        elif pred == 0 and true == 0:\n",
    "            TN += 1; outcome = \"TN\"\n",
    "        elif pred == 1 and true == 0:\n",
    "            FP += 1; outcome = \"FP\"\n",
    "        else:\n",
    "            FN += 1; outcome = \"FN\"\n",
    "\n",
    "        weekly_best.append({\n",
    "            \"Week\": t,\n",
    "            \"True_Label\": true,\n",
    "            \"Pred_Label\": pred,\n",
    "            \"Outcome\": outcome,\n",
    "            \"thu_tue\": float(test[\"thu/tue\"].iloc[0]),\n",
    "        })\n",
    "\n",
    "    df_final = pd.DataFrame(weekly_best)\n",
    "\n",
    "    df_final[\"week_period\"]     = weekly_full.index[df_final[\"Week\"]]\n",
    "    df_final[\"week_start_date\"] = df_final[\"week_period\"].dt.start_time\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Internal Metrics (BASE)\n",
    "    # --------------------------------------------------------\n",
    "    total = TP + TN + FP + FN\n",
    "    prec_overall = precision(TP, FP)\n",
    "    chat_overall = chattiness(TP, FP, FN)\n",
    "    correctness_rate = (TP + TN) / total if total > 0 else 0.0\n",
    "    pct_fp_positive = FP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "\n",
    "    df_final[\"correct\"] = (df_final[\"True_Label\"] == df_final[\"Pred_Label\"]).astype(int)\n",
    "\n",
    "    from statsmodels.sandbox.stats.runs import runstest_1samp\n",
    "    z_runs, p_runs = runstest_1samp(df_final[\"correct\"], correction=False)\n",
    "\n",
    "    randomness_test = {\n",
    "        \"H0\": \"Correctness is random in time.\",\n",
    "        \"z\": float(z_runs),\n",
    "        \"p\": float(p_runs)\n",
    "    }\n",
    "\n",
    "    from scipy.stats import chi2_contingency\n",
    "    df_final[\"chunk\"] = df_final.index // uniformity_binsize\n",
    "    chi2, p_chi, dof, _ = chi2_contingency(pd.crosstab(df_final[\"chunk\"], df_final[\"correct\"]))\n",
    "\n",
    "    uniformity_test = {\n",
    "        \"chi2\": float(chi2),\n",
    "        \"p\": float(p_chi),\n",
    "        \"dof\": int(dof),\n",
    "        \"binsize\": uniformity_binsize,\n",
    "    }\n",
    "\n",
    "    def longest_streak(seq, label):\n",
    "        best = cur = 0\n",
    "        for x in seq:\n",
    "            if x == label:\n",
    "                cur += 1\n",
    "                best = max(best, cur)\n",
    "            else:\n",
    "                cur = 0\n",
    "        return best\n",
    "\n",
    "    longest_tp = longest_streak(df_final[\"Outcome\"], \"TP\")\n",
    "    longest_fp = longest_streak(df_final[\"Outcome\"], \"FP\")\n",
    "\n",
    "    TP_vals = df_final.loc[df_final[\"Outcome\"]==\"TP\",\"thu_tue\"].values\n",
    "    FP_vals = df_final.loc[df_final[\"Outcome\"]==\"FP\",\"thu_tue\"].values\n",
    "    tp_pct = (TP_vals - 1) * 100\n",
    "    fp_pct = (FP_vals - 1) * 100\n",
    "    mistake_asymmetry = float(tp_pct.mean() + fp_pct.mean()) if len(tp_pct) > 0 and len(fp_pct) > 0 else np.nan\n",
    "    trade_frequency   = float((len(TP_vals) + len(FP_vals)) / len(df_final)) if len(df_final) > 0 else 0.0\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Subset Construction with num_subsets Logic (BASE)\n",
    "    # --------------------------------------------------------\n",
    "    if subset_start_date is not None:\n",
    "        ss_dt = pd.to_datetime(subset_start_date)\n",
    "        mask = df_final[\"week_start_date\"] >= ss_dt\n",
    "        if mask.any():\n",
    "            base_start = mask.idxmax()\n",
    "        else:\n",
    "            base_start = len(df_final)\n",
    "    else:\n",
    "        base_start = 0\n",
    "\n",
    "    last_start = len(df_final) - n_weeks\n",
    "    if last_start < base_start:\n",
    "        raise ValueError(\"Not enough data to produce even the final 100-week subset.\")\n",
    "\n",
    "    if num_subsets < 0:\n",
    "        raise ValueError(\"num_subsets must be >= 0\")\n",
    "\n",
    "    if num_subsets > 0:\n",
    "        offsets = np.linspace(0, last_start - base_start, num_subsets + 2, dtype=int)\n",
    "        start_points = offsets[0:num_subsets] + base_start\n",
    "    else:\n",
    "        start_points = []\n",
    "\n",
    "    subsets = []\n",
    "    for s in start_points:\n",
    "        subsets.append((s, df_final.iloc[s:s + n_weeks]))\n",
    "\n",
    "    subsets.append((last_start, df_final.iloc[last_start:last_start + n_weeks]))\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Historical Monte Carlo (BASE)\n",
    "    # --------------------------------------------------------\n",
    "    outcomes_arr = np.array([\"TP\", \"FP\", \"FN\", \"TN\"])\n",
    "\n",
    "    def build_sampler(vals):\n",
    "        vals = np.sort(vals)\n",
    "        if len(vals) == 0:\n",
    "            return None, None\n",
    "        cdf = np.arange(1, len(vals) + 1) / len(vals)\n",
    "        return vals, cdf\n",
    "\n",
    "    def sample(vals, cdf):\n",
    "        u = rng.random()\n",
    "        idx = np.searchsorted(cdf, u)\n",
    "        return vals[min(idx, len(vals) - 1)]\n",
    "\n",
    "    def run_actual(sub):\n",
    "        bank = initial_bank\n",
    "        for _, row in sub.iterrows():\n",
    "            if row[\"Outcome\"] in (\"TP\", \"FP\"):\n",
    "                bank *= row[\"thu_tue\"]\n",
    "            if bank >= upper_thresh or bank <= lower_thresh:\n",
    "                break\n",
    "        return bank\n",
    "\n",
    "    def run_mc_block(p, tp_vals, tp_cdf, fp_vals, fp_cdf):\n",
    "        cdf = np.cumsum(p)\n",
    "        final = np.empty(n_trajectories)\n",
    "        for i in range(n_trajectories):\n",
    "            bank = initial_bank\n",
    "            for _ in range(n_weeks):\n",
    "                r = rng.random()\n",
    "                idx = np.searchsorted(cdf, r)\n",
    "                outcome = outcomes_arr[idx]\n",
    "                if outcome == \"TP\" and tp_vals is not None:\n",
    "                    bank *= sample(tp_vals, tp_cdf)\n",
    "                elif outcome == \"FP\" and fp_vals is not None:\n",
    "                    bank *= sample(fp_vals, fp_cdf)\n",
    "                if bank >= upper_thresh or bank <= lower_thresh:\n",
    "                    break\n",
    "            final[i] = bank\n",
    "        return final\n",
    "\n",
    "    all_sims = []\n",
    "    actual_balances = []\n",
    "    null_percentiles = []\n",
    "\n",
    "    for i, (s, sub) in enumerate(subsets):\n",
    "\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        history = df_final.iloc[:s]\n",
    "\n",
    "        tp_hist = history.loc[history[\"Outcome\"]==\"TP\",\"thu_tue\"].values\n",
    "        fp_hist = history.loc[history[\"Outcome\"]==\"FP\",\"thu_tue\"].values\n",
    "\n",
    "        if len(tp_hist) < 2 or len(fp_hist) < 2:\n",
    "            continue\n",
    "\n",
    "        tp_vals_hist, tp_cdf_hist = build_sampler(tp_hist)\n",
    "        fp_vals_hist, fp_cdf_hist = build_sampler(fp_hist)\n",
    "\n",
    "        p_hist = history[\"Outcome\"].value_counts(normalize=True).reindex(outcomes_arr, fill_value=0).values\n",
    "\n",
    "        sims = run_mc_block(p_hist, tp_vals_hist, tp_cdf_hist, fp_vals_hist, fp_cdf_hist)\n",
    "        all_sims.append(sims)\n",
    "\n",
    "        actual = run_actual(sub)\n",
    "        actual_balances.append(actual)\n",
    "\n",
    "        null_percentiles.append(float(np.mean(sims <= actual)))\n",
    "\n",
    "    if len(all_sims) > 0:\n",
    "        sim_all = np.concatenate(all_sims)\n",
    "    else:\n",
    "        sim_all = np.array([initial_bank])\n",
    "\n",
    "    actual_balances = np.array(actual_balances) if len(actual_balances) > 0 else np.array([initial_bank])\n",
    "    null_percentiles = null_percentiles if len(null_percentiles) > 0 else [0.5]\n",
    "\n",
    "    from scipy.stats import ks_2samp\n",
    "    ks_d, ks_p = ks_2samp(actual_balances, sim_all)\n",
    "\n",
    "    simulated_mean   = float(sim_all.mean())\n",
    "    simulated_median = float(np.median(sim_all))\n",
    "    avg_null         = float(np.mean(null_percentiles))\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Future Monte Carlo (BASE) — uses ALL df_final history\n",
    "    # --------------------------------------------------------\n",
    "    tp_all = df_final.loc[df_final[\"Outcome\"]==\"TP\",\"thu_tue\"].values\n",
    "    fp_all = df_final.loc[df_final[\"Outcome\"]==\"FP\",\"thu_tue\"].values\n",
    "\n",
    "    if len(tp_all) > 1:\n",
    "        tp_vals_all, tp_cdf_all = build_sampler(tp_all)\n",
    "    else:\n",
    "        tp_vals_all, tp_cdf_all = (None, None)\n",
    "\n",
    "    if len(fp_all) > 1:\n",
    "        fp_vals_all, fp_cdf_all = build_sampler(fp_all)\n",
    "    else:\n",
    "        fp_vals_all, fp_cdf_all = (None, None)\n",
    "\n",
    "    p_all = df_final[\"Outcome\"].value_counts(normalize=True).reindex(outcomes_arr, fill_value=0).values\n",
    "\n",
    "    fut = run_mc_block(p_all, tp_vals_all, tp_cdf_all, fp_vals_all, fp_cdf_all)\n",
    "\n",
    "    future_mean     = float(fut.mean())\n",
    "    future_median   = float(np.median(fut))\n",
    "    prob_above_init = float(np.mean(fut > initial_bank))\n",
    "    prob_success    = float(np.mean(fut >= upper_thresh))\n",
    "    prob_failure    = float(np.mean(fut <= lower_thresh))\n",
    "    prob_uncertain  = float(1 - prob_success - prob_failure)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Baseline Comparison (BASE) — all subsets\n",
    "    # --------------------------------------------------------\n",
    "    ratio_always   = []\n",
    "    ratio_random   = []\n",
    "    ratio_alt      = []\n",
    "    ratio_weighted = []\n",
    "\n",
    "    for s, sub in subsets:\n",
    "\n",
    "        model_bal = run_actual(sub)\n",
    "\n",
    "        b = initial_bank\n",
    "        for r in sub[\"thu_tue\"]:\n",
    "            b *= r\n",
    "            if b >= upper_thresh or b <= lower_thresh:\n",
    "                break\n",
    "        ratio_always.append(model_bal / b if b != 0 else np.nan)\n",
    "\n",
    "        ch_prob = len(sub.loc[sub[\"Outcome\"].isin([\"TP\",\"FP\"])]) / len(sub)\n",
    "        b = initial_bank\n",
    "        for r in sub[\"thu_tue\"]:\n",
    "            if rng.random() < ch_prob:\n",
    "                b *= r\n",
    "        ratio_random.append(model_bal / b if b != 0 else np.nan)\n",
    "\n",
    "        b = initial_bank\n",
    "        for i_idx, r in enumerate(sub[\"thu_tue\"]):\n",
    "            if i_idx % 2 == 0:\n",
    "                b *= r\n",
    "        ratio_alt.append(model_bal / b if b != 0 else np.nan)\n",
    "\n",
    "        good_rate = float((sub[\"thu_tue\"] > 1).mean())\n",
    "        b = initial_bank\n",
    "        for r in sub[\"thu_tue\"]:\n",
    "            if rng.random() < good_rate:\n",
    "                b *= r\n",
    "        ratio_weighted.append(model_bal / b if b != 0 else np.nan)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Report Card (BASE)\n",
    "    # --------------------------------------------------------\n",
    "    report = {\n",
    "        \"historical_mc\": {\n",
    "            \"simulated_mean\": simulated_mean,\n",
    "            \"simulated_median\": simulated_median,\n",
    "            \"ks_distance\": float(ks_d),\n",
    "            \"ks_p_value\": float(ks_p),\n",
    "            \"average_null_percentile\": avg_null\n",
    "        },\n",
    "        \"future_mc\": {\n",
    "            \"future_mean\": future_mean,\n",
    "            \"future_median\": future_median,\n",
    "            \"prob_above_initial\": prob_above_init,\n",
    "            \"prob_success\": prob_success,\n",
    "            \"prob_failure\": prob_failure,\n",
    "            \"prob_uncertain\": prob_uncertain\n",
    "        },\n",
    "        \"internal_metrics\": {\n",
    "            \"precision_overall\": prec_overall,\n",
    "            \"chattiness_overall\": chat_overall,\n",
    "            \"correctness_rate\": correctness_rate,\n",
    "            \"trade_frequency\": trade_frequency,\n",
    "            \"mistake_asymmetry_%\": mistake_asymmetry,\n",
    "            \"longest_TP_streak\": longest_tp,\n",
    "            \"longest_FP_streak\": longest_fp,\n",
    "            \"%FP_when_predicted_positive\": pct_fp_positive\n",
    "        },\n",
    "        \"baseline_comparison\": {\n",
    "            \"vs_always_trade\": float(np.nanmean(ratio_always)),\n",
    "            \"vs_random_trader\": float(np.nanmean(ratio_random)),\n",
    "            \"vs_alternate_trader\": float(np.nanmean(ratio_alt)),\n",
    "            \"vs_weighted_coin\": float(np.nanmean(ratio_weighted))\n",
    "        },\n",
    "        \"uniformity_test\": uniformity_test,\n",
    "        \"randomness_test\": randomness_test,\n",
    "    }\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Round all floats in report to 2 decimal places (BASE)\n",
    "    # --------------------------------------------------------\n",
    "    def round_2(obj):\n",
    "        if isinstance(obj, float):\n",
    "            return round(obj, 2)\n",
    "        if isinstance(obj, dict):\n",
    "            return {k: round_2(v) for k, v in obj.items()}\n",
    "        if isinstance(obj, list):\n",
    "            return [round_2(x) for x in obj]\n",
    "        return obj\n",
    "\n",
    "    report = round_2(report)\n",
    "    pprint(report)\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f86de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b978a06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling simulation: 100%|██████████| 1098/1098 [27:41<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'baseline_comparison': {'vs_alternate_trader': 1.0812967396195128,\n",
      "                         'vs_always_trade': 0.9388219549148124,\n",
      "                         'vs_random_trader': 0.8841579281248835,\n",
      "                         'vs_weighted_coin': 0.9716101514990833},\n",
      " 'future_mc': {'future_mean': 119.11756261808581,\n",
      "               'future_median': 117.4032108927795,\n",
      "               'prob_above_initial': 0.80719,\n",
      "               'prob_failure': 0.00048,\n",
      "               'prob_success': 0.0021,\n",
      "               'prob_uncertain': 0.99742},\n",
      " 'historical_mc': {'average_null_percentile': 0.7017659999999999,\n",
      "                   'ks_distance': 0.435628,\n",
      "                   'ks_p_value': 0.22359943919701197,\n",
      "                   'simulated_mean': 113.43315550283613,\n",
      "                   'simulated_median': 110.02676761827134},\n",
      " 'internal_metrics': {'%FP_when_predicted_positive': 0.45436507936507936,\n",
      "                      'chattiness_overall': 0.8330578512396695,\n",
      "                      'correctness_rate': 0.49042844120328166,\n",
      "                      'longest_FP_streak': 6,\n",
      "                      'longest_TP_streak': 9,\n",
      "                      'macro_return_ratio': 1.0466056832250268,\n",
      "                      'micro_return_ratio': 1.0480796352736461,\n",
      "                      'mistake_asymmetry_%': 0.12311534000304691,\n",
      "                      'precision_on_trades': 0.5456349206349206,\n",
      "                      'precision_overall': 0.5456349206349206,\n",
      "                      'return_ratio_gap': -0.0014739520486193314,\n",
      "                      'trade_frequency': 0.4594348222424795},\n",
      " 'randomness_test': {'H0': 'Correctness is random in time.',\n",
      "                     'p': 0.3551814322750749,\n",
      "                     'z': -0.9245857422362671},\n",
      " 'uniformity_test': {'binsize': 104,\n",
      "                     'chi2': 6.911593472688526,\n",
      "                     'dof': 10,\n",
      "                     'p': 0.733763887252251}}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"df\": apple,\n",
    "\n",
    "    \"VALID_WEEKS\": 52,\n",
    "    \"depth_grid\": [2, 3, 4, 5, 6],\n",
    "    \"leaf_grid\": [2, 3, 4, 5, 6],\n",
    "    \"thresholds_tested\": np.linspace(0.01, 0.99, 99),\n",
    "\n",
    "    \"FIXED\": {\n",
    "        \"criterion\": \"entropy\",\n",
    "        \"min_samples_split\": 6,\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"random_state\": 42,\n",
    "    },\n",
    "\n",
    "    \"alpha_p\": 1.0,\n",
    "    \"alpha_c\": 0.01,\n",
    "    \"p_min\": 0.55,\n",
    "    \"c_min\": 0.10,\n",
    "\n",
    "    \"n_trajectories\": 100000,\n",
    "    \"n_weeks\": 100,\n",
    "    \"initial_bank\": 100.0,\n",
    "    \"upper_thresh\": 200.0,\n",
    "    \"lower_thresh\": 60.0,\n",
    "    \"rng_seed\": 42,\n",
    "\n",
    "    \"uniformity_binsize\": 104,\n",
    "\n",
    "    \"cutoff_date\": \"2000-01-01\",\n",
    "    \"subset_start_date\": \"2010-01-01\",\n",
    "    \"num_subsets\": 5,\n",
    "\n",
    "    # =========================================================\n",
    "    # NEW: SUPPORT / RESISTANCE PARAMS (only additions)\n",
    "    # =========================================================\n",
    "    \"SR_SMOOTH_WINDOW\": 5,     # Monday mid smoothing window\n",
    "    \"SR_WINDOW_WEEKS\": 52,     # rolling Monday window length\n",
    "    \"ENVELOPE_A\": 1.0,         # under-penalty for support fit\n",
    "    \"ENVELOPE_B\": 100.0,       # over-penalty for support fit\n",
    "    \"SR_MAX_ITER\": 60,\n",
    "    \"SR_TOL\": 1e-9,\n",
    "}\n",
    "\n",
    "report = full_strategy_pipeline(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1855540c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling simulation: 100%|██████████| 1620/1620 [30:02<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'baseline_comparison': {'vs_alternate_trader': 1.4981777312586806,\n",
      "                         'vs_always_trade': 1.0098909176616684,\n",
      "                         'vs_random_trader': 0.8198168571372062,\n",
      "                         'vs_weighted_coin': 0.9088535106921745},\n",
      " 'future_mc': {'future_mean': 124.50319307456655,\n",
      "               'future_median': 122.4758497008616,\n",
      "               'prob_above_initial': 0.85868,\n",
      "               'prob_failure': 0.0003,\n",
      "               'prob_success': 0.0054,\n",
      "               'prob_uncertain': 0.9943000000000001},\n",
      " 'historical_mc': {'average_null_percentile': 0.692486,\n",
      "                   'ks_distance': 0.563114,\n",
      "                   'ks_p_value': 0.0501086989626232,\n",
      "                   'simulated_mean': 118.6478354838397,\n",
      "                   'simulated_median': 112.5971241425859},\n",
      " 'internal_metrics': {'%FP_when_predicted_positive': 0.46797385620915033,\n",
      "                      'chattiness_overall': 0.9150717703349283,\n",
      "                      'correctness_rate': 0.5138974675725757,\n",
      "                      'longest_FP_streak': 6,\n",
      "                      'longest_TP_streak': 9,\n",
      "                      'macro_return_ratio': 1.0558512081050149,\n",
      "                      'micro_return_ratio': 1.0576662819712104,\n",
      "                      'mistake_asymmetry_%': 0.35659421156026605,\n",
      "                      'precision_on_trades': 0.5320261437908497,\n",
      "                      'precision_overall': 0.5320261437908497,\n",
      "                      'return_ratio_gap': -0.0018150738661955046,\n",
      "                      'trade_frequency': 0.47251389746757255},\n",
      " 'randomness_test': {'H0': 'Correctness is random in time.',\n",
      "                     'p': 0.16543292471009374,\n",
      "                     'z': -1.3870289847698258},\n",
      " 'uniformity_test': {'binsize': 104,\n",
      "                     'chi2': 22.074626054863824,\n",
      "                     'dof': 15,\n",
      "                     'p': 0.10586201658253636}}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"df\": apple,\n",
    "\n",
    "    \"VALID_WEEKS\": 52,\n",
    "    \"depth_grid\": [2, 3, 4, 6],\n",
    "    \"leaf_grid\": [2, 3, 4, 6],\n",
    "    \"thresholds_tested\": np.linspace(0.01, 0.99, 99),\n",
    "\n",
    "    \"FIXED\": {\n",
    "        \"criterion\": \"entropy\",\n",
    "        \"min_samples_split\": 6,\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"random_state\": 42,\n",
    "    },\n",
    "\n",
    "    \"alpha_p\": 1.0,\n",
    "    \"alpha_c\": 0.01,\n",
    "    \"p_min\": 0.55,\n",
    "    \"c_min\": 0.10,\n",
    "\n",
    "    \"n_trajectories\": 100000,\n",
    "    \"n_weeks\": 100,\n",
    "    \"initial_bank\": 100.0,\n",
    "    \"upper_thresh\": 200.0,\n",
    "    \"lower_thresh\": 60.0,\n",
    "    \"rng_seed\": 42,\n",
    "\n",
    "    \"uniformity_binsize\": 104,\n",
    "\n",
    "    \"cutoff_date\": \"1990-01-01\",\n",
    "    \"subset_start_date\": \"2000-01-01\",\n",
    "    \"num_subsets\": 5,\n",
    "\n",
    "    # =========================================================\n",
    "    # NEW: SUPPORT / RESISTANCE PARAMS (only additions)\n",
    "    # =========================================================\n",
    "    \"SR_SMOOTH_WINDOW\": 5,     # Monday mid smoothing window\n",
    "    \"SR_WINDOW_WEEKS\": 52,     # rolling Monday window length\n",
    "    \"ENVELOPE_A\": 1.0,         # under-penalty for support fit\n",
    "    \"ENVELOPE_B\": 100.0,       # over-penalty for support fit\n",
    "    \"SR_MAX_ITER\": 60,\n",
    "    \"SR_TOL\": 1e-9,\n",
    "}\n",
    "\n",
    "report = full_strategy_pipeline(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afa96c1",
   "metadata": {},
   "source": [
    "# with the changed code (before was taking full subset instead of just 100 weeks for historical mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fe561d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling simulation: 100%|██████████| 1620/1620 [28:37<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'baseline_comparison': {'vs_alternate_trader': 1.36,\n",
      "                         'vs_always_trade': 1.05,\n",
      "                         'vs_random_trader': 1.15,\n",
      "                         'vs_weighted_coin': 1.2},\n",
      " 'future_mc': {'future_mean': 117.41,\n",
      "               'future_median': 114.07,\n",
      "               'prob_above_initial': 0.7,\n",
      "               'prob_failure': 0.01,\n",
      "               'prob_success': 0.02,\n",
      "               'prob_uncertain': 0.97},\n",
      " 'historical_mc': {'average_null_percentile': 0.61,\n",
      "                   'ks_distance': 0.33,\n",
      "                   'ks_p_value': 0.54,\n",
      "                   'simulated_mean': 117.9,\n",
      "                   'simulated_median': 113.88},\n",
      " 'internal_metrics': {'%FP_when_predicted_positive': 0.47,\n",
      "                      'chattiness_overall': 0.92,\n",
      "                      'correctness_rate': 0.51,\n",
      "                      'longest_FP_streak': 6,\n",
      "                      'longest_TP_streak': 9,\n",
      "                      'mistake_asymmetry_%': 0.36,\n",
      "                      'precision_overall': 0.53,\n",
      "                      'trade_frequency': 0.47},\n",
      " 'randomness_test': {'H0': 'Correctness is random in time.',\n",
      "                     'p': 0.17,\n",
      "                     'z': -1.39},\n",
      " 'uniformity_test': {'binsize': 104, 'chi2': 22.07, 'dof': 15, 'p': 0.11}}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"df\": apple,\n",
    "\n",
    "    \"VALID_WEEKS\": 52,\n",
    "    \"depth_grid\": [2, 3, 4, 6],\n",
    "    \"leaf_grid\": [2, 3, 4, 6],\n",
    "    \"thresholds_tested\": np.linspace(0.01, 0.99, 99),\n",
    "\n",
    "    \"FIXED\": {\n",
    "        \"criterion\": \"entropy\",\n",
    "        \"min_samples_split\": 6,\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"random_state\": 42,\n",
    "    },\n",
    "\n",
    "    \"alpha_p\": 1.0,\n",
    "    \"alpha_c\": 0.01,\n",
    "    \"p_min\": 0.55,\n",
    "    \"c_min\": 0.10,\n",
    "\n",
    "    \"n_trajectories\": 100000,\n",
    "    \"n_weeks\": 100,\n",
    "    \"initial_bank\": 100.0,\n",
    "    \"upper_thresh\": 200.0,\n",
    "    \"lower_thresh\": 60.0,\n",
    "    \"rng_seed\": 42,\n",
    "\n",
    "    \"uniformity_binsize\": 104,\n",
    "\n",
    "    \"cutoff_date\": \"1990-01-01\",\n",
    "    \"subset_start_date\": \"2000-01-01\",\n",
    "    \"num_subsets\": 5,\n",
    "\n",
    "    # =========================================================\n",
    "    # NEW: SUPPORT / RESISTANCE PARAMS (only additions)\n",
    "    # =========================================================\n",
    "    \"SR_SMOOTH_WINDOW\": 5,     # Monday mid smoothing window\n",
    "    \"SR_WINDOW_WEEKS\": 52,     # rolling Monday window length\n",
    "    \"ENVELOPE_A\": 1.0,         # under-penalty for support fit\n",
    "    \"ENVELOPE_B\": 100.0,       # over-penalty for support fit\n",
    "    \"SR_MAX_ITER\": 60,\n",
    "    \"SR_TOL\": 1e-9,\n",
    "}\n",
    "\n",
    "report = full_strategy_pipeline(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a0af5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "souq_e_commerce_3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
